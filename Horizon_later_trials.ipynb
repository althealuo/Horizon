{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c49a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fe9dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c2c",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d33df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/my_horizon_data_all.csv\", dtype={\"subject\": str})\n",
    "\n",
    "# files = [\n",
    "#     \"data/my_horizon_data.csv\",\n",
    "#     \"data/my_horizon_data_0919.csv\",\n",
    "# ]\n",
    "# df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b9f69bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>block</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>uc</th>\n",
       "      <th>gameLength</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>trial</th>\n",
       "      <th>reward</th>\n",
       "      <th>...</th>\n",
       "      <th>rt0</th>\n",
       "      <th>rt1</th>\n",
       "      <th>rt2</th>\n",
       "      <th>rt3</th>\n",
       "      <th>rt4</th>\n",
       "      <th>rt5</th>\n",
       "      <th>rt6</th>\n",
       "      <th>rt7</th>\n",
       "      <th>rt8</th>\n",
       "      <th>rt9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>184.143661</td>\n",
       "      <td>4.635614</td>\n",
       "      <td>1.122532</td>\n",
       "      <td>2.833540</td>\n",
       "      <td>2.738855</td>\n",
       "      <td>5.263696</td>\n",
       "      <td>5.763985</td>\n",
       "      <td>1.940346</td>\n",
       "      <td>0.937745</td>\n",
       "      <td>2.472841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.184903</td>\n",
       "      <td>1.013671</td>\n",
       "      <td>1.305989</td>\n",
       "      <td>8.874533</td>\n",
       "      <td>2.708196</td>\n",
       "      <td>2.426142</td>\n",
       "      <td>1.115581</td>\n",
       "      <td>1.370487</td>\n",
       "      <td>1.103393</td>\n",
       "      <td>1.046302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832413</td>\n",
       "      <td>0.468084</td>\n",
       "      <td>0.566725</td>\n",
       "      <td>0.445963</td>\n",
       "      <td>1.810017</td>\n",
       "      <td>1.325654</td>\n",
       "      <td>0.892086</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>1.881181</td>\n",
       "      <td>0.576540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830383</td>\n",
       "      <td>0.553779</td>\n",
       "      <td>0.817720</td>\n",
       "      <td>1.686227</td>\n",
       "      <td>0.910277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663673</td>\n",
       "      <td>1.049479</td>\n",
       "      <td>0.692706</td>\n",
       "      <td>3.581879</td>\n",
       "      <td>4.616839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  block  m1  m2  uc  gameLength  age  gender  trial  reward  ...  \\\n",
       "0       0      0  40  36   1           6   18     -99      0      42  ...   \n",
       "1       0      1  60  48   0           6   18     -99      0      67  ...   \n",
       "2       0      2  40  36   0           6   18     -99      0      37  ...   \n",
       "3       0      3  40  48   0           1   18     -99      0      58  ...   \n",
       "4       0      4  40  10   0           1   18     -99      0       4  ...   \n",
       "\n",
       "          rt0       rt1       rt2       rt3       rt4       rt5       rt6  \\\n",
       "0  184.143661  4.635614  1.122532  2.833540  2.738855  5.263696  5.763985   \n",
       "1    1.184903  1.013671  1.305989  8.874533  2.708196  2.426142  1.115581   \n",
       "2    0.832413  0.468084  0.566725  0.445963  1.810017  1.325654  0.892086   \n",
       "3    0.830383  0.553779  0.817720  1.686227  0.910277       NaN       NaN   \n",
       "4    0.663673  1.049479  0.692706  3.581879  4.616839       NaN       NaN   \n",
       "\n",
       "        rt7       rt8       rt9  \n",
       "0  1.940346  0.937745  2.472841  \n",
       "1  1.370487  1.103393  1.046302  \n",
       "2  0.780645  1.881181  0.576540  \n",
       "3       NaN       NaN       NaN  \n",
       "4       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7699168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "--- Feature Data (X) ---\n",
      "     r0   c0    r1   c1    r2   c2    r3   c3\n",
      "0  42.0  0.0  45.0  1.0  42.0  1.0  18.0  1.0\n",
      "1  67.0  0.0  57.0  1.0  56.0  0.0  50.0  1.0\n",
      "2  37.0  1.0  48.0  0.0  23.0  0.0  39.0  1.0\n",
      "3  58.0  1.0  51.0  0.0  28.0  0.0  47.0  1.0\n",
      "4   4.0  1.0  30.0  0.0  11.0  1.0  37.0  0.0\n",
      "   gameLength  uc\n",
      "0           6   1\n",
      "1           6   0\n",
      "2           6   0\n",
      "3           1   0\n",
      "4           1   0\n",
      "\n",
      "--- Target Data (y) ---\n",
      "    c4     c5     c6     c7     c8     c9\n",
      "0  0.0    1.0    1.0    1.0    1.0    1.0\n",
      "1  0.0    0.0    0.0    0.0    0.0    0.0\n",
      "2  0.0    1.0    0.0    0.0    0.0    1.0\n",
      "3  1.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "4  0.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "After scaling:\n",
      "X_seq_train [-0.38649261  0.96221224  0.20634578 -1.00385279  1.15776823  1.03427041\n",
      "  0.33675682  1.00923939] shape (136788, 8)\n",
      "X_static_train [0.999503   1.37599616] shape (136788, 2)\n",
      "y_train c4    0.0\n",
      "c5    1.0\n",
      "c6    1.0\n",
      "c7    1.0\n",
      "c8    1.0\n",
      "c9    1.0\n",
      "Name: 17768, dtype: float64 shape (136788, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq_features = [\n",
    "    'r0', 'c0',\n",
    "    'r1', 'c1',\n",
    "    'r2', 'c2',\n",
    "    'r3', 'c3',\n",
    "]\n",
    "static_features = ['gameLength', 'uc']\n",
    "\n",
    "target = ['c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "\n",
    "\n",
    "X_seq = df[seq_features]\n",
    "X_static = df[static_features]\n",
    "\n",
    "y = df[target]\n",
    "PAD_IDX = -100\n",
    "y = df[['c4','c5','c6','c7','c8','c9']].copy() \n",
    "y = y.fillna(PAD_IDX)\n",
    "\n",
    "\n",
    "print(type(X_seq))\n",
    "X_seq_train, X_seq_test, X_static_train, X_static_test, y_train, y_test = train_test_split(X_seq, X_static, y, test_size=0.2, random_state=42)\n",
    "print(type(X_seq_train))\n",
    "\n",
    "print(\"--- Feature Data (X) ---\")\n",
    "print(X_seq.head())\n",
    "print(X_static.head())\n",
    "print(\"\\n--- Target Data (y) ---\")\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "# split based on original data frame\n",
    "h1_mask = X_static_test['gameLength'] == 1\n",
    "h6_mask = X_static_test['gameLength'] == 6\n",
    "X_static_test_raw = X_static_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_seq_train = scaler.fit_transform(X_seq_train)\n",
    "X_seq_test = scaler.transform(X_seq_test)\n",
    "X_static_train = scaler.fit_transform(X_static_train)\n",
    "X_static_test = scaler.transform(X_static_test)\n",
    "\n",
    "print(\"After scaling:\")\n",
    "print(f'X_seq_train {X_seq_train[0]} shape {X_seq_train.shape}')\n",
    "print(f'X_static_train {X_static_train[0]} shape {X_static_train.shape}')\n",
    "print(f'y_train {y_train.iloc[0]} shape {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a27c6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_LEN: 2\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 4\n",
    "SEQ_LEN = len(seq_features) // TIME_STEPS\n",
    "print(f\"SEQ_LEN: {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7468e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['r0' 'c0']\n",
      "  ['r1' 'c1']\n",
      "  ['r2' 'c2']\n",
      "  ['r3' 'c3']]]\n"
     ]
    }
   ],
   "source": [
    "feature_order_test = np.array(seq_features).reshape(-1, TIME_STEPS, SEQ_LEN)\n",
    "print(feature_order_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe01b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136788, 8)\n",
      "(34197, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(X_seq_train.shape)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf99cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136788, 4, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "[[-0.38649261  0.96221224]\n",
      " [ 0.20634578 -1.00385279]\n",
      " [ 1.15776823  1.03427041]\n",
      " [ 0.33675682  1.00923939]]\n",
      "(34197, 4, 2)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# reshape to (num_samples, time_steps, features)\n",
    "X_seq_train = X_seq_train.reshape(-1, TIME_STEPS, SEQ_LEN)\n",
    "print(X_seq_train.shape)\n",
    "print(type(X_seq_train))\n",
    "print(X_seq_train[0])\n",
    "X_seq_test = X_seq_test.reshape(-1, TIME_STEPS, SEQ_LEN)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4137c6",
   "metadata": {},
   "source": [
    "convert to tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "129e6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_seq_train_tensor = torch.tensor(X_seq_train, dtype=torch.float32) # sklearn output float64, doesn't work with torch\n",
    "X_seq_test_tensor = torch.tensor(X_seq_test, dtype=torch.float32) \n",
    "\n",
    "X_static_train_tensor = torch.tensor(X_static_train, dtype=torch.float32) \n",
    "X_static_test_tensor = torch.tensor(X_static_test, dtype=torch.float32) \n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long) # pandas series to tensor\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddaabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(X_seq_train_tensor, X_static_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_seq_test_tensor, X_static_test_tensor, y_test_tensor), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "acfbc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scaled tensor for h1 h6\n",
    "# convert pandas series -> numpy array -> torch BoolTensor\n",
    "h1_mask_bool = torch.tensor(h1_mask.to_numpy(), dtype=torch.bool)\n",
    "h6_mask_bool = torch.tensor(h6_mask.to_numpy(), dtype=torch.bool)\n",
    "\n",
    "X_seq_test_h1 = torch.tensor(X_seq_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_seq_test_h6 = torch.tensor(X_seq_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "X_static_test_h1 = torch.tensor(X_static_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_static_test_h6 = torch.tensor(X_static_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "y_test_h1 = y_test_tensor[h1_mask_bool]\n",
    "y_test_h6 = y_test_tensor[h6_mask_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75a47a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_seq_test_h1))\n",
    "print(type(X_static_test_h1))\n",
    "print(type(y_test_h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d4de156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader_h1 = DataLoader(TensorDataset(X_seq_test_h1, X_static_test_h1, y_test_h1), batch_size=32, shuffle=False)\n",
    "test_loader_h6 = DataLoader(TensorDataset(X_seq_test_h6, X_static_test_h6, y_test_h6), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71647dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqGRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, \n",
    "                 output_size=2, max_out_len=6, pad_idx=-100):\n",
    "        super(Seq2SeqGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_out_len = max_out_len\n",
    "        self.pad_idx = pad_idx\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.encoder = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # encoder hidden + static\n",
    "        self.fc_static = nn.Linear(hidden_size + static_input_size, hidden_size)\n",
    "\n",
    "        # Decoder: input = one-hot choice vector (dim = output_size)\n",
    "        self.decoder = nn.GRU(output_size, hidden_size, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, seq_x, static_x, targets=None, teacher_forcing_ratio=1.0):\n",
    "        # --- Encode ---\n",
    "        _, h_n = self.encoder(seq_x)        # h_n: [1, B, hidden]\n",
    "        h_n = h_n.squeeze(0)                # [B, hidden]\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        encoder_output = self.fc_static(combined).unsqueeze(0)  # [1, B, hidden]\n",
    "\n",
    "        # --- Decode ---\n",
    "        outputs = []\n",
    "        batch_size = seq_x.size(0)\n",
    "        device = seq_x.device\n",
    "\n",
    "        decoder_input = torch.zeros(batch_size, 1, self.output_size, device=device)  # start token (all zeros)\n",
    "        hidden = encoder_output\n",
    "\n",
    "        for t in range(self.max_out_len):\n",
    "            dec_out, hidden = self.decoder(decoder_input, hidden)  # dec_out: [B, 1, hidden]\n",
    "            logits = self.out(dec_out)                            # [B, 1, output_size]\n",
    "            outputs.append(logits)\n",
    "\n",
    "            # Teacher forcing toggle\n",
    "            use_teacher_forcing = (targets is not None) and (random.random() < teacher_forcing_ratio)\n",
    "            if use_teacher_forcing:\n",
    "                target_t = targets[:, t]                          # [B]\n",
    "                one_hot = torch.zeros(batch_size, self.output_size, device=device)\n",
    "                valid_mask = (target_t != self.pad_idx)\n",
    "                one_hot[valid_mask, target_t[valid_mask]] = 1.0\n",
    "                decoder_input = one_hot.unsqueeze(1)              # [B, 1, output_size]\n",
    "            else:\n",
    "                decoder_input = torch.softmax(logits, dim=-1)     # [B, 1, output_size]\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # [B, max_out_len, output_size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd32b8",
   "metadata": {},
   "source": [
    "# train / eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1c5649cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_accuracy(logits, labels, pad_idx=-100):\n",
    "    preds = logits.argmax(dim=-1)  # [B, L]\n",
    "    L = labels.size(1)\n",
    "    accs = []\n",
    "\n",
    "    for t in range(L):\n",
    "        mask = labels[:, t] != pad_idx\n",
    "        if mask.sum() > 0:\n",
    "            correct = (preds[:, t][mask] == labels[:, t][mask]).sum().item()\n",
    "            accs.append(correct / mask.sum().item())\n",
    "        else:\n",
    "            accs.append(float('nan')) \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "139239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, pad_idx=-100):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for seq_inputs, static_inputs, labels in train_loader:\n",
    "        seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(seq_inputs, static_inputs, targets=labels, teacher_forcing_ratio=1.0)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = labels != pad_idx\n",
    "        correct += (preds[mask] == labels[mask]).sum().item()\n",
    "        total += mask.sum().item()\n",
    "        train_loss += loss.item() * seq_inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device, pad_idx=-100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    step_acc_sum = None\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_inputs, static_inputs, labels in test_loader:\n",
    "            seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "            logits = model(seq_inputs, static_inputs, teacher_forcing_ratio=0.0)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "            \n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask = labels != pad_idx\n",
    "            correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "            total_loss += loss.item() * seq_inputs.size(0)\n",
    "\n",
    "            # step-wise accuracy for this batch\n",
    "            batch_step_accs = stepwise_accuracy(logits, labels, pad_idx)\n",
    "            if step_acc_sum is None:\n",
    "                step_acc_sum = [0.0] * len(batch_step_accs)\n",
    "            for i, acc in enumerate(batch_step_accs):\n",
    "                if not (acc != acc):  # skip NaNs\n",
    "                    step_acc_sum[i] += acc\n",
    "            n_batches += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    step_accs = [a / n_batches for a in step_acc_sum]\n",
    "    return accuracy, avg_loss, step_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bd35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, test_loader_h1, test_loader_h6,\n",
    "                       criterion, optimizer, device, epochs, pad_idx=-100):\n",
    "    train_loss_prog, train_acc_prog = [], []\n",
    "    test_loss_prog, test_acc_prog = [], []\n",
    "    test_acc_h1_prog, test_loss_h1_prog, test_step_h1_prog = [], [], []\n",
    "    test_acc_h6_prog, test_loss_h6_prog, test_step_h6_prog = [], [], []\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience, epochs_no_improve = 5, 0\n",
    "    final_epoch = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_loss = train(model, train_loader, criterion, optimizer, device, pad_idx)\n",
    "        test_acc, test_loss, _ = test(model, test_loader, criterion, device, pad_idx)\n",
    "        test_acc_h1, test_loss_h1, step_acc_h1 = test(model, test_loader_h1, criterion, device, pad_idx)\n",
    "        test_acc_h6, test_loss_h6, step_acc_h6 = test(model, test_loader_h6, criterion, device, pad_idx)\n",
    "\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}: overall {test_acc:.3f}, H1 {test_acc_h1:.3f}, H6 {test_acc_h6:.3f}\")\n",
    "\n",
    "        # log\n",
    "        train_acc_prog.append(train_acc); train_loss_prog.append(train_loss)\n",
    "        test_acc_prog.append(test_acc); test_loss_prog.append(test_loss)\n",
    "        test_acc_h1_prog.append(test_acc_h1); test_loss_h1_prog.append(test_loss_h1); test_step_h1_prog.append(step_acc_h1)\n",
    "        test_acc_h6_prog.append(test_acc_h6); test_loss_h6_prog.append(test_loss_h6); test_step_h6_prog.append(step_acc_h6)\n",
    "\n",
    "        # early stopping\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}, best loss {best_loss:.4f}\")\n",
    "            final_epoch = epoch+1\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"train_acc\": train_acc_prog,\n",
    "        \"train_loss\": train_loss_prog,\n",
    "        \"test_acc\": test_acc_prog,\n",
    "        \"test_loss\": test_loss_prog,\n",
    "        \"h1_acc\": test_acc_h1_prog,\n",
    "        \"h1_loss\": test_loss_h1_prog,\n",
    "        \"h1_step_acc\": test_step_h1_prog,\n",
    "        \"h6_acc\": test_acc_h6_prog,\n",
    "        \"h6_loss\": test_loss_h6_prog,\n",
    "        \"h6_step_acc\": test_step_h6_prog,\n",
    "        \"final_epoch\": final_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f45961",
   "metadata": {},
   "source": [
    "# running experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83333872",
   "metadata": {},
   "source": [
    "## single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8c0ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TinyAttentionNoProj().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0205db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# epochs = 100\n",
    "# loss_prog, acc_prog, acc_h1_prog, acc_h6_prog, final_epoch = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7a02a",
   "metadata": {},
   "source": [
    "## multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3395551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    # \"RNN\": RNN().to(device),\n",
    "    # \"LSTM\": LSTM().to(device),\n",
    "    # \"GRU\": GRU().to(device),\n",
    "    # \"TinyGRU\": TinyGRU().to(device),\n",
    "    # \"Transformer\": TransformerEncoderPositionalEncoding().to(device),\n",
    "    # \"SelfAttention\": SelfAttentionOnly().to(device),\n",
    "    # \"TinyAttentionNoProj\": TinyAttentionNoProj().to(device),\n",
    "    \"Seq2SeqGRU\": Seq2SeqGRU().to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b82e7321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: Seq2SeqGRU\n",
      "Epoch 1: overall 0.769, H1 0.815, H6 0.761\n",
      "Early stopping at epoch 7, best loss 0.5123\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'step_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 24\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      6\u001b[0m history \u001b[38;5;241m=\u001b[39m train_and_evaluate(\n\u001b[0;32m      7\u001b[0m     model,\n\u001b[0;32m      8\u001b[0m     train_loader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m model_dict[model_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step_acc_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_acc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,       \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step_acc_h1_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_acc_h1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step_acc_h6_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_acc_h6\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc_h1_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh1_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss_h1_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc_h6_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh6_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss_h6_prog\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh6_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     32\u001b[0m }\n",
      "\u001b[1;31mKeyError\u001b[0m: 'step_acc'"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    history = train_and_evaluate(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        test_loader_h1,\n",
    "        test_loader_h6,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    model_dict[model_name] = {\n",
    "        \"model\": model,\n",
    "        \"train_loss_prog\": history[\"train_loss\"],\n",
    "        \"train_acc_prog\": history[\"train_acc\"],\n",
    "        \"test_loss_prog\": history[\"test_loss\"],\n",
    "        \"test_acc_prog\": history[\"test_acc\"],\n",
    "        \"test_step_acc_prog\": history[\"step_acc\"],       \n",
    "        \"test_step_acc_h1_prog\": history[\"step_acc_h1\"], \n",
    "        \"test_step_acc_h6_prog\": history[\"step_acc_h6\"], \n",
    "        \"test_acc_h1_prog\": history[\"h1_acc\"],\n",
    "        \"test_loss_h1_prog\": history[\"h1_loss\"],\n",
    "        \"test_acc_h6_prog\": history[\"h6_acc\"],\n",
    "        \"test_loss_h6_prog\": history[\"h6_loss\"],\n",
    "        \"final_epoch\": history[\"final_epoch\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a559b0",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "632187f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "840699a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_h6_stepwise(history, model_name=\"Seq2SeqGRU\"):\n",
    "    final_acc_h6 = history[\"h6_step_acc\"][-1]   # [acc_c4,...,acc_c9]\n",
    "    final_acc_h1 = history[\"h1_acc\"][-1]        # single value\n",
    "\n",
    "    trials = [f\"c{i}\" for i in range(4, 10)]\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(trials, final_acc_h6, marker=\"o\", linestyle=\"-\", color=\"blue\", label=\"H6\")\n",
    "    plt.axhline(y=final_acc_h1, color=\"red\", linestyle=\"--\", label=\"H1\")\n",
    "\n",
    "    plt.ylim(0.7, 0.85)\n",
    "    plt.xlabel(\"Game trial\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name}\")\n",
    "    plt.legend()\n",
    "    # plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8535e18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_h6_stepwise(history, model_name=\"Seq2SeqGRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1e8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
