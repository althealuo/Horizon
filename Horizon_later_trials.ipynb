{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c2c",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/my_horizon_data_all.csv\", dtype={\"subject\": str})\n",
    "\n",
    "# files = [\n",
    "#     \"data/my_horizon_data.csv\",\n",
    "#     \"data/my_horizon_data_0919.csv\",\n",
    "# ]\n",
    "# df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_features = [\n",
    "    'r0', 'c0',\n",
    "    'r1', 'c1',\n",
    "    'r2', 'c2',\n",
    "    'r3', 'c3',\n",
    "]\n",
    "static_features = ['gameLength', 'uc']\n",
    "\n",
    "target = 'c4'\n",
    "\n",
    "X_seq = df[seq_features]\n",
    "X_static = df[static_features]\n",
    "y = df[target]\n",
    "\n",
    "print(type(X_seq))\n",
    "X_seq_train, X_seq_test, X_static_train, X_static_test, y_train, y_test = train_test_split(X_seq, X_static, y, test_size=0.2, random_state=42)\n",
    "print(type(X_seq_train))\n",
    "\n",
    "print(\"--- Feature Data (X) ---\")\n",
    "print(X_seq.head())\n",
    "print(X_static.head())\n",
    "print(\"\\n--- Target Data (y) ---\")\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "# split based on original data frame\n",
    "h1_mask = X_static_test['gameLength'] == 1\n",
    "h6_mask = X_static_test['gameLength'] == 6\n",
    "X_static_test_raw = X_static_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_seq_train = scaler.fit_transform(X_seq_train)\n",
    "X_seq_test = scaler.transform(X_seq_test)\n",
    "X_static_train = scaler.fit_transform(X_static_train)\n",
    "X_static_test = scaler.transform(X_static_test)\n",
    "\n",
    "\n",
    "\n",
    "# X_seq_train = X_seq_train.to_numpy()\n",
    "# X_seq_test = X_seq_test.to_numpy()\n",
    "# X_static_train = X_static_train.to_numpy()\n",
    "# X_static_test = X_static_test.to_numpy()\n",
    "\n",
    "print(\"After scaling:\")\n",
    "print(f'X_seq_train {X_seq_train[0]}')\n",
    "print(f'X_static_train {X_static_train[0]}')\n",
    "print(f'y_train {y_train.iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = seq_features.__len__() // 4 \n",
    "print(f\"SEQ_LEN: {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order_test = np.array(seq_features).reshape(-1, 4, SEQ_LEN)\n",
    "print(feature_order_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_seq_train.shape)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to (num_samples, time_steps, features)\n",
    "X_seq_train = X_seq_train.reshape(-1, 4, SEQ_LEN)\n",
    "print(X_seq_train.shape)\n",
    "print(type(X_seq_train))\n",
    "print(X_seq_train[0])\n",
    "X_seq_test = X_seq_test.reshape(-1, 4, SEQ_LEN)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4137c6",
   "metadata": {},
   "source": [
    "convert to tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_seq_train_tensor = torch.tensor(X_seq_train, dtype=torch.float32) # sklearn output float64, doesn't work with torch\n",
    "X_seq_test_tensor = torch.tensor(X_seq_test, dtype=torch.float32) \n",
    "\n",
    "X_static_train_tensor = torch.tensor(X_static_train, dtype=torch.float32) \n",
    "X_static_test_tensor = torch.tensor(X_static_test, dtype=torch.float32) \n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long) # pandas series to tensor\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(X_seq_train_tensor, X_static_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_seq_test_tensor, X_static_test_tensor, y_test_tensor), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scaled tensor for h1 h6\n",
    "# convert pandas series -> numpy array -> torch BoolTensor\n",
    "h1_mask_bool = torch.tensor(h1_mask.to_numpy(), dtype=torch.bool)\n",
    "h6_mask_bool = torch.tensor(h6_mask.to_numpy(), dtype=torch.bool)\n",
    "\n",
    "X_seq_test_h1 = torch.tensor(X_seq_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_seq_test_h6 = torch.tensor(X_seq_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "X_static_test_h1 = torch.tensor(X_static_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_static_test_h6 = torch.tensor(X_static_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "y_test_h1 = y_test_tensor[h1_mask_bool]\n",
    "y_test_h6 = y_test_tensor[h6_mask_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a47a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_seq_test_h1))\n",
    "print(type(X_static_test_h1))\n",
    "print(type(y_test_h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader_h1 = DataLoader(TensorDataset(X_seq_test_h1, X_static_test_h1, y_test_h1), batch_size=32, shuffle=False)\n",
    "test_loader_h6 = DataLoader(TensorDataset(X_seq_test_h6, X_static_test_h6, y_test_h6), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(seq_input_size, hidden_size, batch_first=True, nonlinearity='tanh')\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        rnn_out, h_n = self.rnn(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=128, output_size=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 64), # combine static inputs\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        rnn_out, (h_n, c_n) = self.lstm(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15347c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        gru_out, h_n = self.gru(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate GRU output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd76ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=2, output_size=2):\n",
    "        super(TinyGRU, self).__init__()\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 2), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        gru_out, h_n = self.gru(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate GRU output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ccda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingSin(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4):\n",
    "        super(PositionalEncodingSin, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderPositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(TransformerEncoderPositionalEncoding, self).__init__()\n",
    "        self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncodingSin(d_model=hidden_size, max_len=4)\n",
    "\n",
    "        self.transformer = nn.TransformerEncoderLayer( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            d_model=hidden_size, \n",
    "            nhead=4, \n",
    "            dropout=0.0,\n",
    "            dim_feedforward=128,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3)\n",
    "        x_encoded = self.pos_encoder(x_seq_proj)\n",
    "        x_trans = self.transformer(x_encoded) # (batch, 4, hidden_size)\n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionOnly(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(SelfAttentionOnly, self).__init__()\n",
    "        self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncodingSin(d_model=hidden_size, max_len=4)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            embed_dim=hidden_size, \n",
    "            num_heads=8, \n",
    "            dropout=0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3) -> (batch, 4, hidden_size)\n",
    "        x_encoded = self.pos_encoder(x_seq_proj)\n",
    "        x_trans, _ = self.attn(x_encoded, x_encoded, x_encoded) # (batch, 4, hidden_size)\n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAttentionNoProj(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=2, output_size=2):\n",
    "        super(TinyAttentionNoProj, self).__init__()\n",
    "        # self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        # self.pos_encoder = PositionalEncodingSin(d_model=seq_input_size, max_len=4)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            embed_dim=seq_input_size, \n",
    "            num_heads=1, \n",
    "            dropout=0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(seq_input_size, seq_input_size),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(seq_input_size + static_input_size, 1), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        # x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3) -> (batch, 4, hidden_size)\n",
    "        # x_encoded = self.pos_encoder(seq_x)\n",
    "        x_trans, _ = self.attn(seq_x, seq_x, seq_x) # (batch, 4, hidden_size)\n",
    "\n",
    "        # x_trans = self.mlp(x_trans)\n",
    "        \n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd32b8",
   "metadata": {},
   "source": [
    "# train / eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device): \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = len(train_loader)\n",
    "\n",
    "    for seq_inputs, static_inputs, labels in train_loader:\n",
    "        seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(seq_inputs, static_inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    avg_loss = train_loss / total\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total = len(test_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq_inputs, static_inputs, labels in test_loader:\n",
    "            seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            logits = model(seq_inputs, static_inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / total\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    train_loss_prog, train_acc_prog = [], []\n",
    "\n",
    "    test_loss_prog, test_acc_prog = [], []\n",
    "\n",
    "    test_acc_h1_prog, test_loss_h1_prog = [], []\n",
    "    test_acc_h6_prog, test_loss_h6_prog = [], []\n",
    "\n",
    "    epochs_without_improvement = 0 # for early stopping\n",
    "    best_loss = float('inf')\n",
    "    PATIENCE = 8\n",
    "    final_epoch = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        test_acc, test_loss = test(model, test_loader, criterion, device)\n",
    "        test_acc_h1, test_loss_h1 = test(model, test_loader_h1, criterion, device)\n",
    "        test_acc_h6, test_loss_h6 = test(model, test_loader_h6, criterion, device)\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss: {test_loss:.4f} | overall: {test_acc:.4f} | H1 {test_acc_h1:.4f} | H6 {test_acc_h6:.4f}\")\n",
    "\n",
    "        train_acc_prog.append(train_acc)\n",
    "        train_loss_prog.append(train_loss)\n",
    "\n",
    "        test_loss_prog.append(test_loss)\n",
    "        test_acc_prog.append(test_acc)\n",
    "\n",
    "        test_acc_h1_prog.append(test_acc_h1)\n",
    "        test_loss_h1_prog.append(test_loss_h1)\n",
    "\n",
    "        test_acc_h6_prog.append(test_acc_h6)\n",
    "        test_loss_h6_prog.append(test_loss_h6)\n",
    "\n",
    "        # early stopping\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement > PATIENCE: \n",
    "            print(f\"Early stopping triggered: epoch {epoch+1} best_loss {best_loss:.4f}\")\n",
    "            final_epoch = epoch+1\n",
    "            break\n",
    "\n",
    "    return train_loss_prog, train_acc_prog, test_loss_prog, test_acc_prog, test_acc_h1_prog, test_loss_h1_prog, test_acc_h6_prog, test_loss_h6_prog, final_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f45961",
   "metadata": {},
   "source": [
    "# running experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83333872",
   "metadata": {},
   "source": [
    "## single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TinyAttentionNoProj().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# epochs = 100\n",
    "# loss_prog, acc_prog, acc_h1_prog, acc_h6_prog, final_epoch = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7a02a",
   "metadata": {},
   "source": [
    "## multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"RNN\": RNN().to(device),\n",
    "    \"LSTM\": LSTM().to(device),\n",
    "    \"GRU\": GRU().to(device),\n",
    "    \"TinyGRU\": TinyGRU().to(device),\n",
    "    \"Transformer\": TransformerEncoderPositionalEncoding().to(device),\n",
    "    \"SelfAttention\": SelfAttentionOnly().to(device),\n",
    "    \"TinyAttentionNoProj\": TinyAttentionNoProj().to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_loss_prog, train_acc_prog, test_loss_prog, test_acc_prog, test_acc_h1_prog, test_loss_h1_prog, test_acc_h6_prog, test_loss_h6_prog, final_epoch = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)\n",
    "    model_dict[model_name] = {\n",
    "        \"model\": model,\n",
    "        \"train_loss_prog\": train_loss_prog,\n",
    "        \"train_acc_prog\": train_acc_prog,\n",
    "        \"test_loss_prog\": test_loss_prog,\n",
    "        \"test_acc_prog\": test_acc_prog,\n",
    "        \"test_acc_h1_prog\": test_acc_h1_prog,\n",
    "        \"test_loss_h1_prog\": test_loss_h1_prog,\n",
    "        \"test_acc_h6_prog\": test_acc_h6_prog,\n",
    "        \"test_loss_h6_prog\": test_loss_h6_prog,\n",
    "        \"final_epoch\": final_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a559b0",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632187f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b8a2a",
   "metadata": {},
   "source": [
    "## single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training and testing loss\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(epochs), loss_prog, label='Training Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss over epochs')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e21596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot testing accuracy\n",
    "# def plot_accuracy(accuracy_progress_list):\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     for label, acc in accuracy_progress_list:\n",
    "#         plt.plot(range(epochs), acc, label=label)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy (%)')\n",
    "#     plt.title('Test Accuracy over epochs')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_accuracy([('test accuracy', acc_prog)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2288055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_accuracy([('test accuracy', acc_prog), ('h1 accuracy', acc_h1_prog), ('h6 accuracy', acc_h6_prog)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1152da",
   "metadata": {},
   "source": [
    "## multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9aebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and testing loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for model_name, data in model_dict.items():\n",
    "    loss_prog = data[\"test_loss_prog\"]\n",
    "    final_epoch = data[\"final_epoch\"]\n",
    "    plt.plot(range(final_epoch), loss_prog, label=f'{model_name} Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1546dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot testing accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "for model_name, data in model_dict.items():\n",
    "    acc_prog = data[\"test_acc_prog\"]\n",
    "    final_epoch = data[\"final_epoch\"]\n",
    "    plt.plot(range(final_epoch), acc_prog, label=f'{model_name} Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6659a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(model_dict)\n",
    "\n",
    "# Two color ramps\n",
    "blue_cmap = plt.get_cmap('Blues')\n",
    "red_cmap  = plt.get_cmap('Reds')\n",
    "\n",
    "# helper to pick a shade between lo..hi in the colormap\n",
    "def shade(cmap, i, n, lo=0.35, hi=0.85):\n",
    "    if n <= 1:\n",
    "        t = (lo+hi)/2\n",
    "    else:\n",
    "        t = lo + (hi - lo) * (i / (n - 1))\n",
    "    return cmap(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389aa0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot testing accuracy h1 vs h6\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (model_name, data) in enumerate(model_dict.items()):\n",
    "    acc_h1_prog = data[\"test_acc_h1_prog\"]\n",
    "    acc_h6_prog = data[\"test_acc_h6_prog\"]\n",
    "    final_epoch = data[\"final_epoch\"]\n",
    "    plt.plot(range(final_epoch), acc_h1_prog, label=f'{model_name} H1 Accuracy', color=shade(blue_cmap, i, n))\n",
    "    plt.plot(range(final_epoch), acc_h6_prog, label=f'{model_name} H6 Accuracy', color=shade(red_cmap, i, n))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy over epochs')\n",
    "plt.legend(\n",
    "    ncol=2,      \n",
    "    fontsize=9, \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489bb903",
   "metadata": {},
   "source": [
    "## error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_means = []\n",
    "h6_means = []\n",
    "\n",
    "h1_stds = []\n",
    "h6_stds = []\n",
    "\n",
    "for model_name, data in model_dict.items():\n",
    "    acc_h1 = data[\"acc_h1_prog\"]\n",
    "    acc_h6 = data[\"acc_h6_prog\"]\n",
    "\n",
    "    h1_means.append(np.mean(acc_h1))\n",
    "    h6_means.append(np.mean(acc_h6))\n",
    "    h1_stds.append(np.std(acc_h1))\n",
    "    h6_stds.append(np.std(acc_h6))\n",
    "\n",
    "\n",
    "names = list(model_dict.keys())\n",
    "y_pos = np.arange(len(names))\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# H1\n",
    "ax.errorbar(h1_means, y_pos - 0.1, xerr=h1_stds, fmt='o', color='tab:blue',\n",
    "            label=\"H1\", capsize=4)\n",
    "\n",
    "# H6\n",
    "ax.errorbar(h6_means, y_pos + 0.1, xerr=h6_stds, fmt='o', color='tab:orange',\n",
    "            label=\"H6\", capsize=4)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlabel(\"Accuracy\")\n",
    "ax.set_ylabel(\"Model\")\n",
    "ax.set_title(\"Model Accuracy with Error Bars (H1 vs H6)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366201b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
