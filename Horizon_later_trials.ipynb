{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47441db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import utils.data_processing as data_processing\n",
    "importlib.reload(data_processing)\n",
    "from utils.data_processing import get_dataloaders, set_seed, save_output, get_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe9dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c2c",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "--- Feature Data (X) ---\n",
      "     r0   c0    r1   c1    r2   c2    r3   c3\n",
      "0  42.0  0.0  45.0  1.0  42.0  1.0  18.0  1.0\n",
      "1  67.0  0.0  57.0  1.0  56.0  0.0  50.0  1.0\n",
      "2  37.0  1.0  48.0  0.0  23.0  0.0  39.0  1.0\n",
      "3  58.0  1.0  51.0  0.0  28.0  0.0  47.0  1.0\n",
      "4   4.0  1.0  30.0  0.0  11.0  1.0  37.0  0.0\n",
      "   gameLength  uc\n",
      "0           6   1\n",
      "1           6   0\n",
      "2           6   0\n",
      "3           1   0\n",
      "4           1   0\n",
      "\n",
      "--- Target Data (y) ---\n",
      "    c4     c5     c6     c7     c8     c9\n",
      "0  0.0    1.0    1.0    1.0    1.0    1.0\n",
      "1  0.0    0.0    0.0    0.0    0.0    0.0\n",
      "2  0.0    1.0    0.0    0.0    0.0    1.0\n",
      "3  1.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "4  0.0 -100.0 -100.0 -100.0 -100.0 -100.0\n",
      "After scaling:\n",
      "X_seq_train [-0.38649261  0.96221224  0.20634578 -1.00385279  1.15776823  1.03427041\n",
      "  0.33675682  1.00923939] shape (136788, 8)\n",
      "X_static_train [0.999503   1.37599616] shape (136788, 2)\n",
      "y_train c4    0.0\n",
      "c5    1.0\n",
      "c6    1.0\n",
      "c7    1.0\n",
      "c8    1.0\n",
      "c9    1.0\n",
      "Name: 17768, dtype: float64 shape (136788, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq_features = [\n",
    "    'r0', 'c0',\n",
    "    'r1', 'c1',\n",
    "    'r2', 'c2',\n",
    "    'r3', 'c3',\n",
    "]\n",
    "static_features = ['gameLength', 'uc']\n",
    "\n",
    "target = ['c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "\n",
    "\n",
    "X_seq = df[seq_features]\n",
    "X_static = df[static_features]\n",
    "\n",
    "y = df[target]\n",
    "PAD_IDX = -100\n",
    "y = df[['c4','c5','c6','c7','c8','c9']].copy() \n",
    "y = y.fillna(PAD_IDX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4137c6",
   "metadata": {},
   "source": [
    "convert to tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 4\n",
    "SEQ_LEN = len(seq_features) // TIME_STEPS\n",
    "BATCH_SIZE=32\n",
    "train_loader, test_loader, test_loader_h1, test_loader_h6 = get_dataloaders(X_seq, X_static, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71647dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import (\n",
    "    Seq2SeqGRU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd32b8",
   "metadata": {},
   "source": [
    "# train / eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5649cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_accuracy(logits, labels, pad_idx=-100):\n",
    "    preds = logits.argmax(dim=-1)  # [B, L]\n",
    "    L = labels.size(1)\n",
    "    accs = []\n",
    "\n",
    "    for t in range(L):\n",
    "        mask = labels[:, t] != pad_idx\n",
    "        if mask.sum() > 0:\n",
    "            correct = (preds[:, t][mask] == labels[:, t][mask]).sum().item()\n",
    "            accs.append(correct / mask.sum().item())\n",
    "        else:\n",
    "            accs.append(float('nan')) \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, pad_idx=-100):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for seq_inputs, static_inputs, labels in train_loader:\n",
    "        seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(seq_inputs, static_inputs, targets=labels, teacher_forcing_ratio=1.0)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = labels != pad_idx\n",
    "        correct += (preds[mask] == labels[mask]).sum().item()\n",
    "        total += mask.sum().item()\n",
    "        train_loss += loss.item() * seq_inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device, pad_idx=-100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    step_acc_sum = None\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_inputs, static_inputs, labels in test_loader:\n",
    "            seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "            logits = model(seq_inputs, static_inputs, teacher_forcing_ratio=0.0)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "            \n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask = labels != pad_idx\n",
    "            correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "            total_loss += loss.item() * seq_inputs.size(0)\n",
    "\n",
    "            # step-wise accuracy for this batch\n",
    "            batch_step_accs = stepwise_accuracy(logits, labels, pad_idx)\n",
    "            if step_acc_sum is None:\n",
    "                step_acc_sum = [0.0] * len(batch_step_accs)\n",
    "            for i, acc in enumerate(batch_step_accs):\n",
    "                if not (acc != acc):  # skip NaNs\n",
    "                    step_acc_sum[i] += acc\n",
    "            n_batches += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    step_accs = [a / n_batches for a in step_acc_sum]\n",
    "    return accuracy, avg_loss, step_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, test_loader_h1, test_loader_h6,\n",
    "                       criterion, optimizer, device, epochs, pad_idx=-100):\n",
    "    train_loss_prog, train_acc_prog = [], []\n",
    "    test_loss_prog, test_acc_prog = [], []\n",
    "    test_acc_h1_prog, test_loss_h1_prog, test_step_h1_prog = [], [], []\n",
    "    test_acc_h6_prog, test_loss_h6_prog, test_step_h6_prog = [], [], []\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience, epochs_no_improve = 5, 0\n",
    "    final_epoch = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_loss = train(model, train_loader, criterion, optimizer, device, pad_idx)\n",
    "        test_acc, test_loss, _ = test(model, test_loader, criterion, device, pad_idx)\n",
    "        test_acc_h1, test_loss_h1, step_acc_h1 = test(model, test_loader_h1, criterion, device, pad_idx)\n",
    "        test_acc_h6, test_loss_h6, step_acc_h6 = test(model, test_loader_h6, criterion, device, pad_idx)\n",
    "\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}: overall {test_acc:.3f}, H1 {test_acc_h1:.3f}, H6 {test_acc_h6:.3f}\")\n",
    "\n",
    "        # log\n",
    "        train_acc_prog.append(train_acc); train_loss_prog.append(train_loss)\n",
    "        test_acc_prog.append(test_acc); test_loss_prog.append(test_loss)\n",
    "        test_acc_h1_prog.append(test_acc_h1); test_loss_h1_prog.append(test_loss_h1); test_step_h1_prog.append(step_acc_h1)\n",
    "        test_acc_h6_prog.append(test_acc_h6); test_loss_h6_prog.append(test_loss_h6); test_step_h6_prog.append(step_acc_h6)\n",
    "\n",
    "        # early stopping\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}, best loss {best_loss:.4f}\")\n",
    "            final_epoch = epoch+1\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"train_acc\": train_acc_prog,\n",
    "        \"train_loss\": train_loss_prog,\n",
    "        \"test_acc\": test_acc_prog,\n",
    "        \"test_loss\": test_loss_prog,\n",
    "        \"h1_acc\": test_acc_h1_prog,\n",
    "        \"h1_loss\": test_loss_h1_prog,\n",
    "        \"h1_step_acc\": test_step_h1_prog,\n",
    "        \"h6_acc\": test_acc_h6_prog,\n",
    "        \"h6_loss\": test_loss_h6_prog,\n",
    "        \"h6_step_acc\": test_step_h6_prog,\n",
    "        \"final_epoch\": final_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f45961",
   "metadata": {},
   "source": [
    "# running experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"Seq2SeqGRU\": Seq2SeqGRU(SEQ_LEN).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e7321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: Seq2SeqGRU\n",
      "Epoch 1: overall 0.770, H1 0.816, H6 0.763\n",
      "Early stopping at epoch 9, best loss 0.5214\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    history = train_and_evaluate(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        test_loader_h1,\n",
    "        test_loader_h6,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    model_dict[model_name] = {\n",
    "        \"model\": model,\n",
    "        **history\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fdb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output(model_dict, \"output_later_trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fc58c",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_h6_stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_h6_stepwise(history, model_name=\"Seq2SeqGRU\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
