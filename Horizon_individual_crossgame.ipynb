{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe9dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c2c",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/my_horizon_data_all.csv\", dtype={\"subject\": str})\n",
    "\n",
    "# files = [\n",
    "#     \"data/my_horizon_data.csv\",\n",
    "#     \"data/my_horizon_data_0919.csv\",\n",
    "# ]\n",
    "# df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9f69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.head(5000)  # For quicker testing !!!!! REMEBER TO RMOVE IT!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72679ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 1384\n"
     ]
    }
   ],
   "source": [
    "num_subjects = df[\"subject\"].nunique()\n",
    "print(\"Number of unique subjects:\", num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ba6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # boundary flag\n",
    "# df['boundary'] = (df['block'] != df.groupby('subject')['block'].shift(1)).astype(int)\n",
    "# print(df[['subject', 'block', 'boundary']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Data (X) ---\n",
      "     r0   c0    r1   c1    r2   c2    r3   c3\n",
      "0  42.0  0.0  45.0  1.0  42.0  1.0  18.0  1.0\n",
      "1  67.0  0.0  57.0  1.0  56.0  0.0  50.0  1.0\n",
      "2  37.0  1.0  48.0  0.0  23.0  0.0  39.0  1.0\n",
      "3  58.0  1.0  51.0  0.0  28.0  0.0  47.0  1.0\n",
      "4   4.0  1.0  30.0  0.0  11.0  1.0  37.0  0.0\n",
      "   gameLength  uc  subj_0  subj_1  subj_100  subj_1000  subj_1001  \\\n",
      "0           6   1    True   False     False      False      False   \n",
      "1           6   0    True   False     False      False      False   \n",
      "2           6   0    True   False     False      False      False   \n",
      "3           1   0    True   False     False      False      False   \n",
      "4           1   0    True   False     False      False      False   \n",
      "\n",
      "   subj_1001.0_TMS  subj_1002  subj_1002.0_TMS  ...  subj_990  subj_991  \\\n",
      "0            False      False            False  ...     False     False   \n",
      "1            False      False            False  ...     False     False   \n",
      "2            False      False            False  ...     False     False   \n",
      "3            False      False            False  ...     False     False   \n",
      "4            False      False            False  ...     False     False   \n",
      "\n",
      "   subj_992  subj_993  subj_994  subj_995  subj_996  subj_997  subj_998  \\\n",
      "0     False     False     False     False     False     False     False   \n",
      "1     False     False     False     False     False     False     False   \n",
      "2     False     False     False     False     False     False     False   \n",
      "3     False     False     False     False     False     False     False   \n",
      "4     False     False     False     False     False     False     False   \n",
      "\n",
      "   subj_999  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "\n",
      "[5 rows x 1386 columns]\n",
      "\n",
      "--- Target Data (y) ---\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: c4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seq_features = [\n",
    "    'r0', 'c0',\n",
    "    'r1', 'c1',\n",
    "    'r2', 'c2',\n",
    "    'r3', 'c3',\n",
    "]\n",
    "static_features = ['gameLength', 'uc']\n",
    "\n",
    "target = 'c4'\n",
    "\n",
    "subj_onehot = pd.get_dummies(df['subject'], prefix='subj')\n",
    "df_static = pd.concat([df[static_features], subj_onehot], axis=1)\n",
    "\n",
    "X_seq = df[seq_features]\n",
    "X_static = df_static\n",
    "y = df[target]\n",
    "\n",
    "# split based on subjects\n",
    "subjects = df['subject'].unique()\n",
    "train_subj, test_subj = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = df['subject'].isin(train_subj)\n",
    "test_mask  = df['subject'].isin(test_subj)\n",
    "\n",
    "X_seq_train = df.loc[train_mask, seq_features]\n",
    "X_seq_test  = df.loc[test_mask, seq_features]\n",
    "\n",
    "X_static_train = df_static.loc[train_mask]\n",
    "X_static_test  = df_static.loc[test_mask]\n",
    "\n",
    "y_train = y[train_mask]\n",
    "y_test  = y[test_mask]\n",
    "\n",
    "\n",
    "# split based on original data frame\n",
    "h1_mask = X_static_test['gameLength'] == 1\n",
    "h6_mask = X_static_test['gameLength'] == 6\n",
    "X_static_test_raw = X_static_test.copy()\n",
    "\n",
    "\n",
    "# separate numeric static vs one-hot\n",
    "onehot_cols = [c for c in X_static.columns if c.startswith('subj_')]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_seq_train = scaler.fit_transform(X_seq_train)\n",
    "X_seq_test = scaler.transform(X_seq_test)\n",
    "\n",
    "X_static_train_num = scaler.fit_transform(X_static_train[static_features])\n",
    "X_static_test_num  = scaler.transform(X_static_test[static_features])\n",
    "\n",
    "# keep one-hot untouched\n",
    "X_static_train_oh = X_static_train[onehot_cols].to_numpy()\n",
    "X_static_test_oh  = X_static_test[onehot_cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27c6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_LEN: 2\n",
      "STATIC_LEN: 1386\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = seq_features.__len__() // 4 \n",
    "print(f\"SEQ_LEN: {SEQ_LEN}\")\n",
    "STATIC_LEN = X_static_train.shape[1]\n",
    "print(f\"STATIC_LEN: {STATIC_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7468e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['r0' 'c0']\n",
      "  ['r1' 'c1']\n",
      "  ['r2' 'c2']\n",
      "  ['r3' 'c3']]]\n"
     ]
    }
   ],
   "source": [
    "feature_order_test = np.array(seq_features).reshape(-1, 4, SEQ_LEN)\n",
    "print(feature_order_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9547fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 9.99078375e-01  1.37538975e+00]]\n",
      "\n",
      " [[ 9.99078375e-01 -6.74679601e-04]]\n",
      "\n",
      " [[ 9.99078375e-01 -6.74679601e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.00092248e+00 -6.74679601e-04]]\n",
      "\n",
      " [[-1.00092248e+00 -1.37673911e+00]]\n",
      "\n",
      " [[-1.00092248e+00  1.37538975e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_static_train_num[:, np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes:\n",
      "X_seq_train: (136652, 4, 4) example [[-0.44340398 -1.03825727  0.99907837  1.37538975]\n",
      " [-0.26885783  0.99938183  0.99907837  1.37538975]\n",
      " [-0.49591546  1.03400207  0.99907837  1.37538975]\n",
      " [-1.84556152  1.00375379  0.99907837  1.37538975]]\n",
      "X_static_train: (136652, 1384)\n",
      "y_train: (136652,)\n"
     ]
    }
   ],
   "source": [
    "X_seq_train = X_seq_train.reshape(-1, 4, SEQ_LEN)\n",
    "X_seq_test  = X_seq_test.reshape(-1, 4, SEQ_LEN)\n",
    "\n",
    "\n",
    "# Repeat numeric static info across 4 time steps, and append to sequential inputs\n",
    "X_static_train_num_rep = np.repeat(X_static_train_num[:, np.newaxis, :], 4, axis=1)\n",
    "X_static_test_num_rep  = np.repeat(X_static_test_num[:, np.newaxis, :], 4, axis=1)\n",
    "\n",
    "X_seq_train = np.concatenate([X_seq_train, X_static_train_num_rep], axis=2)\n",
    "X_seq_test  = np.concatenate([X_seq_test, X_static_test_num_rep], axis=2)\n",
    "\n",
    "# Final static input = subject one-hot only\n",
    "X_static_train = X_static_train_oh\n",
    "X_static_test  = X_static_test_oh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4137c6",
   "metadata": {},
   "source": [
    "convert to tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129e6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_seq_train_tensor = torch.tensor(X_seq_train, dtype=torch.float32) # sklearn output float64, doesn't work with torch\n",
    "X_seq_test_tensor = torch.tensor(X_seq_test, dtype=torch.float32) \n",
    "\n",
    "X_static_train_tensor = torch.tensor(X_static_train, dtype=torch.float32) \n",
    "X_static_test_tensor = torch.tensor(X_static_test, dtype=torch.float32) \n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long) # pandas series to tensor\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2baf858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique block counts: [160 128 121 120 125 320 224 192 134 129 147 100  82 106 123 163 157 149\n",
      "  90 137 118 102  92  94  51  75  98  74  25  85  89 119  93  62  69 104\n",
      "  86  88  80  76  59 109  53  83 113  96 101 103  72  68  99  58  95  78\n",
      "  61 107  35  87  79  14]\n"
     ]
    }
   ],
   "source": [
    "block_counts = df.groupby('subject')['block'].nunique()\n",
    "print(\"Unique block counts:\", block_counts.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddaabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(TensorDataset(X_seq_train_tensor, X_static_train_tensor, y_train_tensor), batch_size=32, shuffle=False)\n",
    "# test_loader = DataLoader(TensorDataset(X_seq_test_tensor, X_static_test_tensor, y_test_tensor), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41ca303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index mapping *within* train/test subsets\n",
    "train_subjects_series = df.loc[train_mask, 'subject'].reset_index(drop=True)\n",
    "test_subjects_series  = df.loc[test_mask, 'subject'].reset_index(drop=True)\n",
    "\n",
    "# Now build mapping of subject -> tensor-relative indices\n",
    "train_subject_indices = {\n",
    "    subj: np.where(train_subjects_series == subj)[0]\n",
    "    for subj in train_subj\n",
    "}\n",
    "test_subject_indices = {\n",
    "    subj: np.where(test_subjects_series == subj)[0]\n",
    "    for subj in test_subj\n",
    "}\n",
    "\n",
    "# Make per-subject tensors (now indices are valid)\n",
    "train_groups = [\n",
    "    (subj,\n",
    "     X_seq_train_tensor[idx],\n",
    "     X_static_train_tensor[idx],\n",
    "     y_train_tensor[idx])\n",
    "    for subj, idx in train_subject_indices.items()\n",
    "]\n",
    "\n",
    "test_groups = [\n",
    "    (subj,\n",
    "     X_seq_test_tensor[idx],\n",
    "     X_static_test_tensor[idx],\n",
    "     y_test_tensor[idx])\n",
    "    for subj, idx in test_subject_indices.items()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53aba66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectLoader:\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "    def __iter__(self):\n",
    "        for subj, X_seq, X_static, y in self.groups:\n",
    "            yield subj, X_seq, X_static, y\n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "train_loader = SubjectLoader(train_groups)\n",
    "test_loader  = SubjectLoader(test_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acfbc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scaled tensor for h1 h6\n",
    "# convert pandas series -> numpy array -> torch BoolTensor\n",
    "h1_idx = torch.tensor(h1_mask.to_numpy(), dtype=torch.bool)\n",
    "h6_idx = torch.tensor(h6_mask.to_numpy(), dtype=torch.bool)\n",
    "\n",
    "X_seq_test_h1 = X_seq_test_tensor[h1_idx]\n",
    "X_seq_test_h6 = X_seq_test_tensor[h6_idx]\n",
    "\n",
    "X_static_test_h1 = X_static_test_tensor[h1_idx]\n",
    "X_static_test_h6 = X_static_test_tensor[h6_idx]\n",
    "\n",
    "y_test_h1 = y_test_tensor[h1_idx]\n",
    "y_test_h6 = y_test_tensor[h6_idx]\n",
    "\n",
    "test_groups_h1 = [(\"H1\", X_seq_test_h1, X_static_test_h1, y_test_h1)]\n",
    "test_groups_h6 = [(\"H6\", X_seq_test_h6, X_static_test_h6, y_test_h6)]\n",
    "\n",
    "test_loader_h1 = SubjectLoader(test_groups_h1)\n",
    "test_loader_h6 = SubjectLoader(test_groups_h6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4593b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "891d60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNbeta(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, hidden_size=64, output_size=2):\n",
    "        super(RNNbeta, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.logit_beta = nn.Parameter(torch.tensor(0.0))  # initialize logit(0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, h=None):\n",
    "        if h is not None:\n",
    "            beta = torch.sigmoid(self.logit_beta)  # constrain between 0 and 1\n",
    "            h = beta * h.detach()\n",
    "        gru_out, h_n = self.rnn(seq_x, h)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        output = self.fc(h_n)\n",
    "        return output, h_n.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9534dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMbeta(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, hidden_size=64, output_size=2):\n",
    "        super(LSTMbeta, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.logit_beta = nn.Parameter(torch.tensor(0.0))  # initialize logit(0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, h=None):\n",
    "        if h is not None:\n",
    "            beta = torch.sigmoid(self.logit_beta)  # constrain between 0 and 1\n",
    "            h = beta * h.detach()\n",
    "        lstm_out, (h_n, c_n) = self.lstm(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        output = self.fc(h_n)\n",
    "        return output, h_n.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15347c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, hidden_size=64, output_size=2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, h=None):\n",
    "        gru_out, h_n = self.gru(seq_x, h)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        output = self.fc(h_n)\n",
    "        return output, h_n.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef98b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUbeta(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, hidden_size=64, output_size=2):\n",
    "        super(GRUbeta, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.logit_beta = nn.Parameter(torch.tensor(0.0))  # initialize logit(0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, h=None):\n",
    "        if h is not None:\n",
    "            beta = torch.sigmoid(self.logit_beta)  # constrain between 0 and 1\n",
    "            h = beta * h.detach()\n",
    "        gru_out, h_n = self.gru(seq_x, h)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        output = self.fc(h_n)\n",
    "        return output, h_n.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd76ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGRUbeta(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, hidden_size=2, output_size=2):\n",
    "        super(TinyGRUbeta, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.logit_beta = nn.Parameter(torch.tensor(0.0))  # initialize logit(0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, h=None):\n",
    "        if h is not None:\n",
    "            beta = torch.sigmoid(self.logit_beta)  # constrain between 0 and 1\n",
    "            h = beta * h.detach()\n",
    "        gru_out, h_n = self.gru(seq_x, h)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        output = self.fc(h_n)\n",
    "        return output, h_n.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd32b8",
   "metadata": {},
   "source": [
    "# train / eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0  # total number of games (not batches)\n",
    "\n",
    "    BATCH_GAMES = 32  # tune this as needed\n",
    "\n",
    "    for subj_id, seqs, statics, labels in train_loader:\n",
    "        h = None\n",
    "        subj_loss = 0.0 \n",
    "\n",
    "        for i in range(0, len(seqs), BATCH_GAMES):\n",
    "            x_batch = seqs[i:i+BATCH_GAMES].to(device)\n",
    "            y_batch = labels[i:i+BATCH_GAMES].to(device)\n",
    "\n",
    "            if h is not None and h.size(1) != len(x_batch):\n",
    "                h = torch.zeros(1, len(x_batch), model.hidden_size, device=device)\n",
    "\n",
    "            preds, h = model(x_batch, h)\n",
    "            loss = criterion(preds, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "\n",
    "            subj_loss += loss.item() * len(x_batch)  # scale by batch size\n",
    "            correct += (preds.argmax(dim=1) == y_batch).sum().item()\n",
    "            total += len(x_batch)\n",
    "\n",
    "        total_loss += subj_loss\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for subj_id, seqs, statics, labels in test_loader:\n",
    "            h = None  # reset per subject\n",
    "\n",
    "            seqs = seqs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            for i in range(len(seqs)):\n",
    "                x_seq = seqs[i].unsqueeze(0)\n",
    "                y_true = labels[i].unsqueeze(0)\n",
    "\n",
    "                preds, h = model(x_seq, h)\n",
    "                loss = criterion(preds, y_true)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                correct += (preds.argmax(dim=1) == y_true).sum().item()\n",
    "                total += 1\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bd35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    train_loss_prog, train_acc_prog = [], []\n",
    "    test_loss_prog, test_acc_prog = [], []\n",
    "    test_acc_h1_prog, test_loss_h1_prog = [], []\n",
    "    test_acc_h6_prog, test_loss_h6_prog = [], []\n",
    "\n",
    "    epochs_without_improvement = 0\n",
    "    best_loss = float('inf')\n",
    "    PATIENCE = 5\n",
    "    final_epoch = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ----- TRAIN -----\n",
    "        train_acc, train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        # ----- EVALUATE -----\n",
    "        test_acc, test_loss = test(model, test_loader, criterion, device)\n",
    "        test_acc_h1, test_loss_h1 = test(model, test_loader_h1, criterion, device)\n",
    "        test_acc_h6, test_loss_h6 = test(model, test_loader_h6, criterion, device)\n",
    "\n",
    "        # ----- LOG -----\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            # If your model returns β (GRUβ)\n",
    "            if hasattr(model, \"logit_beta\"):\n",
    "                beta_val = torch.sigmoid(model.logit_beta).item()\n",
    "                print(f\"Epoch {epoch+1}: Loss: {test_loss:.4f} | overall: {test_acc:.4f} | H1 {test_acc_h1:.4f} | H6 {test_acc_h6:.4f} | β={beta_val:.3f}\")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}: Loss: {test_loss:.4f} | overall: {test_acc:.4f} | H1 {test_acc_h1:.4f} | H6 {test_acc_h6:.4f}\")\n",
    "\n",
    "        # ----- STORE PROGRESS -----\n",
    "        train_acc_prog.append(train_acc)\n",
    "        train_loss_prog.append(train_loss)\n",
    "\n",
    "        test_loss_prog.append(test_loss)\n",
    "        test_acc_prog.append(test_acc)\n",
    "\n",
    "        test_acc_h1_prog.append(test_acc_h1)\n",
    "        test_loss_h1_prog.append(test_loss_h1)\n",
    "        test_acc_h6_prog.append(test_acc_h6)\n",
    "        test_loss_h6_prog.append(test_loss_h6)\n",
    "\n",
    "        # ----- EARLY STOPPING -----\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement > PATIENCE:\n",
    "            print(f\"Early stopping triggered: epoch {epoch+1}, best_loss {best_loss:.4f}\")\n",
    "            final_epoch = epoch + 1\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"train_loss_prog\": train_loss_prog,\n",
    "        \"train_acc_prog\": train_acc_prog,\n",
    "        \"test_loss_prog\": test_loss_prog,\n",
    "        \"test_acc_prog\": test_acc_prog,\n",
    "        \"test_acc_h1_prog\": test_acc_h1_prog,\n",
    "        \"test_loss_h1_prog\": test_loss_h1_prog,\n",
    "        \"test_acc_h6_prog\": test_acc_h6_prog,\n",
    "        \"test_loss_h6_prog\": test_loss_h6_prog,\n",
    "        \"final_epoch\": final_epoch\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f45961",
   "metadata": {},
   "source": [
    "# running experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7a02a",
   "metadata": {},
   "source": [
    "## multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3395551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"LSTM\": LSTMbeta().to(device),\n",
    "    \"RNN\": RNNbeta().to(device),\n",
    "    \"GRU\": GRU().to(device),\n",
    "    \"GRUbeta\": GRUbeta().to(device),\n",
    "    \"TinyGRU\": TinyGRUbeta().to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b82e7321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: LSTM\n",
      "Epoch 1: Loss: 0.5118 | overall: 0.7696 | H1 0.8107 | H6 0.7285 | β=0.500\n",
      "Epoch 10: Loss: 0.4981 | overall: 0.7754 | H1 0.8149 | H6 0.7359 | β=0.500\n",
      "Early stopping triggered: epoch 19, best_loss 0.4974\n",
      "LSTM: final learned β = 0.500\n",
      "\n",
      "Training model: RNN\n",
      "Epoch 1: Loss: 0.5216 | overall: 0.7590 | H1 0.7951 | H6 0.7221 | β=0.293\n",
      "Epoch 10: Loss: 0.5067 | overall: 0.7698 | H1 0.8071 | H6 0.7329 | β=0.160\n",
      "Early stopping triggered: epoch 18, best_loss 0.5065\n",
      "RNN: final learned β = 0.173\n",
      "\n",
      "Training model: GRU\n",
      "Epoch 1: Loss: 0.5194 | overall: 0.7635 | H1 0.8028 | H6 0.7247\n",
      "Epoch 10: Loss: 0.5132 | overall: 0.7633 | H1 0.8021 | H6 0.7276\n",
      "Early stopping triggered: epoch 12, best_loss 0.5085\n",
      "\n",
      "Training model: GRUbeta\n",
      "Epoch 1: Loss: 0.5149 | overall: 0.7677 | H1 0.8055 | H6 0.7279 | β=0.293\n",
      "Epoch 10: Loss: 0.4993 | overall: 0.7747 | H1 0.8128 | H6 0.7357 | β=0.113\n",
      "Epoch 20: Loss: 0.5003 | overall: 0.7733 | H1 0.8129 | H6 0.7333 | β=0.169\n",
      "Early stopping triggered: epoch 21, best_loss 0.4987\n",
      "GRUbeta: final learned β = 0.174\n",
      "\n",
      "Training model: TinyGRU\n",
      "Epoch 1: Loss: 0.5286 | overall: 0.7580 | H1 0.7929 | H6 0.7215 | β=0.134\n",
      "Epoch 10: Loss: 0.5147 | overall: 0.7693 | H1 0.8063 | H6 0.7323 | β=0.008\n",
      "Epoch 20: Loss: 0.5121 | overall: 0.7690 | H1 0.8074 | H6 0.7304 | β=0.003\n",
      "Epoch 30: Loss: 0.5107 | overall: 0.7705 | H1 0.8089 | H6 0.7320 | β=0.001\n",
      "Epoch 40: Loss: 0.5090 | overall: 0.7712 | H1 0.8091 | H6 0.7334 | β=0.000\n",
      "Epoch 50: Loss: 0.5080 | overall: 0.7721 | H1 0.8109 | H6 0.7331 | β=0.000\n",
      "Epoch 60: Loss: 0.5073 | overall: 0.7721 | H1 0.8107 | H6 0.7334 | β=0.000\n",
      "Epoch 70: Loss: 0.5069 | overall: 0.7718 | H1 0.8103 | H6 0.7333 | β=0.000\n",
      "Epoch 80: Loss: 0.5067 | overall: 0.7723 | H1 0.8105 | H6 0.7341 | β=0.000\n",
      "Epoch 90: Loss: 0.5066 | overall: 0.7721 | H1 0.8101 | H6 0.7340 | β=0.000\n",
      "Early stopping triggered: epoch 93, best_loss 0.5064\n",
      "TinyGRU: final learned β = 0.000\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    history = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)\n",
    "    if hasattr(model, \"logit_beta\"):\n",
    "        beta_val = torch.sigmoid(model.logit_beta).item()\n",
    "        print(f\"{model_name}: final learned β = {beta_val:.3f}\")\n",
    "    model_dict[model_name] = {\n",
    "        \"model\": model,\n",
    "        **history   # unpack dictionary contents into this model’s record\n",
    "    }\n",
    "    # torch.save(model.state_dict(), f\"model_weights_crossgame_{model_name}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c6b9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_history = {}\n",
    "\n",
    "for model_name, content in model_dict.items():\n",
    "    # content = {\"model\": <model_object>, \"train_acc\": ..., \"test_acc\": ..., ...}\n",
    "    filtered = {k: v for k, v in content.items() if k != \"model\"}\n",
    "    dump_history[model_name] = filtered\n",
    "# store the outputs \n",
    "import json\n",
    "with open(\"output_cross_games.json\", \"w\") as f:\n",
    "    json.dump(dump_history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
