{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe9dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c2c",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/my_horizon_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9f69bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>block</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>uc</th>\n",
       "      <th>gameLength</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>trial</th>\n",
       "      <th>reward</th>\n",
       "      <th>...</th>\n",
       "      <th>rt0</th>\n",
       "      <th>rt1</th>\n",
       "      <th>rt2</th>\n",
       "      <th>rt3</th>\n",
       "      <th>rt4</th>\n",
       "      <th>rt5</th>\n",
       "      <th>rt6</th>\n",
       "      <th>rt7</th>\n",
       "      <th>rt8</th>\n",
       "      <th>rt9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.416998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.317264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.383654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1.367162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.267352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  block  m1  m2  uc  gameLength  age  gender  trial  reward  ...  \\\n",
       "0   1001.0      0  40  32   1           1   26       0      0      51  ...   \n",
       "1   1001.0      1  60  48   1           1   26       0      0      52  ...   \n",
       "2   1001.0      2  40  20  -1           1   26       0      0      49  ...   \n",
       "3   1001.0      3  36  40   0           1   26       0      0      32  ...   \n",
       "4   1001.0      4  60  52   1           1   26       0      0      52  ...   \n",
       "\n",
       "    rt0   rt1   rt2   rt3       rt4  rt5  rt6  rt7  rt8  rt9  \n",
       "0 -99.0 -99.0 -99.0 -99.0  0.416998  NaN  NaN  NaN  NaN  NaN  \n",
       "1 -99.0 -99.0 -99.0 -99.0  0.317264  NaN  NaN  NaN  NaN  NaN  \n",
       "2 -99.0 -99.0 -99.0 -99.0  0.383654  NaN  NaN  NaN  NaN  NaN  \n",
       "3 -99.0 -99.0 -99.0 -99.0  1.367162  NaN  NaN  NaN  NaN  NaN  \n",
       "4 -99.0 -99.0 -99.0 -99.0  0.267352  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72679ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 610\n"
     ]
    }
   ],
   "source": [
    "num_subjects = df[\"subject\"].nunique()\n",
    "print(\"Number of unique subjects:\", num_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7699168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (98362, 44)\n",
      "New df shape: (610, 44)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "--- Feature Data (X) ---\n",
      "     r0   c0    r1   c1    r2   c2    r3   c3\n",
      "0  51.0  0.0  47.0  1.0  33.0  1.0  18.0  1.0\n",
      "1  51.0  0.0  47.0  1.0  33.0  1.0  18.0  1.0\n",
      "2  51.0  0.0  47.0  1.0  33.0  1.0  18.0  1.0\n",
      "3  51.0  0.0  47.0  1.0  33.0  1.0  18.0  1.0\n",
      "4  51.0  0.0  47.0  1.0  33.0  1.0  18.0  1.0\n",
      "   gameLength  uc\n",
      "0           1   1\n",
      "1           1   1\n",
      "2           1   1\n",
      "3           1   1\n",
      "4           1   1\n",
      "\n",
      "--- Target Data (y) ---\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: c4, dtype: float64\n",
      "After scaling:\n",
      "X_seq_train [ 0.41047858  0.9918366   1.49963376 -1.34335316  0.26195108  0.62792174\n",
      "  0.68400015  1.01653005]\n",
      "X_static_train [0.86189161 0.91379511]\n",
      "y_train 0.0\n"
     ]
    }
   ],
   "source": [
    "# same as sklearn \n",
    "\n",
    "seq_features = [\n",
    "    'r0', 'c0',\n",
    "    'r1', 'c1',\n",
    "    'r2', 'c2',\n",
    "    'r3', 'c3',\n",
    "]\n",
    "static_features = ['gameLength', 'uc']\n",
    "\n",
    "target = 'c4'\n",
    "\n",
    "# only keep the first trial per subject\n",
    "print(f\"Original df shape: {df.shape}\")\n",
    "df = df.groupby('subject').head(1).reset_index(drop=True)\n",
    "print(f\"New df shape: {df.shape}\")\n",
    "\n",
    "X_seq = df[seq_features]\n",
    "X_static = df[static_features]\n",
    "y = df[target]\n",
    "\n",
    "print(type(X_seq))\n",
    "X_seq_train, X_seq_test, X_static_train, X_static_test, y_train, y_test = train_test_split(X_seq, X_static, y, test_size=0.2, random_state=42)\n",
    "print(type(X_seq_train))\n",
    "\n",
    "print(\"--- Feature Data (X) ---\")\n",
    "print(X_seq.head())\n",
    "print(X_static.head())\n",
    "print(\"\\n--- Target Data (y) ---\")\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "# split based on original data frame\n",
    "h1_mask = X_static_test['gameLength'] == 1\n",
    "h6_mask = X_static_test['gameLength'] == 6\n",
    "X_static_test_raw = X_static_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_seq_train = scaler.fit_transform(X_seq_train)\n",
    "X_seq_test = scaler.transform(X_seq_test)\n",
    "X_static_train = scaler.fit_transform(X_static_train)\n",
    "X_static_test = scaler.transform(X_static_test)\n",
    "\n",
    "\n",
    "\n",
    "# X_seq_train = X_seq_train.to_numpy()\n",
    "# X_seq_test = X_seq_test.to_numpy()\n",
    "# X_static_train = X_static_train.to_numpy()\n",
    "# X_static_test = X_static_test.to_numpy()\n",
    "\n",
    "print(\"After scaling:\")\n",
    "print(f'X_seq_train {X_seq_train[0]}')\n",
    "print(f'X_static_train {X_static_train[0]}')\n",
    "print(f'y_train {y_train.iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27c6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_LEN: 2\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = seq_features.__len__() // 4 \n",
    "print(f\"SEQ_LEN: {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7468e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['r0' 'c0']\n",
      "  ['r1' 'c1']\n",
      "  ['r2' 'c2']\n",
      "  ['r3' 'c3']]]\n"
     ]
    }
   ],
   "source": [
    "feature_order_test = np.array(seq_features).reshape(-1, 4, SEQ_LEN)\n",
    "print(feature_order_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe01b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488, 8)\n",
      "(122, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(X_seq_train.shape)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf99cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488, 4, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.41047858  0.9918366 ]\n",
      " [ 1.49963376 -1.34335316]\n",
      " [ 0.26195108  0.62792174]\n",
      " [ 0.68400015  1.01653005]]\n",
      "(122, 4, 2)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# reshape to (num_samples, time_steps, features)\n",
    "X_seq_train = X_seq_train.reshape(-1, 4, SEQ_LEN)\n",
    "print(X_seq_train.shape)\n",
    "print(type(X_seq_train))\n",
    "print(X_seq_train[0])\n",
    "X_seq_test = X_seq_test.reshape(-1, 4, SEQ_LEN)\n",
    "print(X_seq_test.shape)\n",
    "print(type(X_seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4137c6",
   "metadata": {},
   "source": [
    "convert to tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129e6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_seq_train_tensor = torch.tensor(X_seq_train, dtype=torch.float32) # sklearn output float64, doesn't work with torch\n",
    "X_seq_test_tensor = torch.tensor(X_seq_test, dtype=torch.float32) \n",
    "\n",
    "X_static_train_tensor = torch.tensor(X_static_train, dtype=torch.float32) \n",
    "X_static_test_tensor = torch.tensor(X_static_test, dtype=torch.float32) \n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long) # pandas series to tensor\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddaabfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(X_seq_train_tensor, X_static_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_seq_test_tensor, X_static_test_tensor, y_test_tensor), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acfbc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scaled tensor for h1 h6\n",
    "# convert pandas series -> numpy array -> torch BoolTensor\n",
    "h1_mask_bool = torch.tensor(h1_mask.to_numpy(), dtype=torch.bool)\n",
    "h6_mask_bool = torch.tensor(h6_mask.to_numpy(), dtype=torch.bool)\n",
    "\n",
    "X_seq_test_h1 = torch.tensor(X_seq_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_seq_test_h6 = torch.tensor(X_seq_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "X_static_test_h1 = torch.tensor(X_static_test[h1_mask_bool], dtype=torch.float32)\n",
    "X_static_test_h6 = torch.tensor(X_static_test[h6_mask_bool], dtype=torch.float32)\n",
    "\n",
    "y_test_h1 = y_test_tensor[h1_mask_bool]\n",
    "y_test_h6 = y_test_tensor[h6_mask_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a47a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_seq_test_h1))\n",
    "print(type(X_static_test_h1))\n",
    "print(type(y_test_h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4de156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader_h1 = DataLoader(TensorDataset(X_seq_test_h1, X_static_test_h1, y_test_h1), batch_size=32, shuffle=False)\n",
    "test_loader_h6 = DataLoader(TensorDataset(X_seq_test_h6, X_static_test_h6, y_test_h6), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "891d60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(seq_input_size, hidden_size, batch_first=True, nonlinearity='tanh')\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        rnn_out, h_n = self.rnn(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9534dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=128, output_size=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 64), # combine static inputs\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        rnn_out, (h_n, c_n) = self.lstm(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15347c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        gru_out, h_n = self.gru(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate GRU output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd76ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGRU(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=2, output_size=2):\n",
    "        super(TinyGRU, self).__init__()\n",
    "        self.gru = nn.GRU(seq_input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 2), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        gru_out, h_n = self.gru(seq_x)\n",
    "        h_n = h_n.squeeze(0)\n",
    "        # concatenate GRU output with static features\n",
    "        combined = torch.cat((h_n, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b0ccda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingSin(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4):\n",
    "        super(PositionalEncodingSin, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e50cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderPositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(TransformerEncoderPositionalEncoding, self).__init__()\n",
    "        self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncodingSin(d_model=hidden_size, max_len=4)\n",
    "\n",
    "        self.transformer = nn.TransformerEncoderLayer( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            d_model=hidden_size, \n",
    "            nhead=4, \n",
    "            dropout=0.0,\n",
    "            dim_feedforward=128,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3)\n",
    "        x_encoded = self.pos_encoder(x_seq_proj)\n",
    "        x_trans = self.transformer(x_encoded) # (batch, 4, hidden_size)\n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f40fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionOnly(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=64, output_size=2):\n",
    "        super(SelfAttentionOnly, self).__init__()\n",
    "        self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncodingSin(d_model=hidden_size, max_len=4)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            embed_dim=hidden_size, \n",
    "            num_heads=8, \n",
    "            dropout=0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + static_input_size, 32), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3) -> (batch, 4, hidden_size)\n",
    "        x_encoded = self.pos_encoder(x_seq_proj)\n",
    "        x_trans, _ = self.attn(x_encoded, x_encoded, x_encoded) # (batch, 4, hidden_size)\n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc4b1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAttentionNoProj(nn.Module):\n",
    "    def __init__(self, seq_input_size=SEQ_LEN, static_input_size=2, hidden_size=2, output_size=2):\n",
    "        super(TinyAttentionNoProj, self).__init__()\n",
    "        # self.input_fc = nn.Linear(seq_input_size, hidden_size)\n",
    "        # self.pos_encoder = PositionalEncodingSin(d_model=seq_input_size, max_len=4)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention( # (batch_size, seq_len=4, feature_dim (projected to higher dim))\n",
    "            embed_dim=seq_input_size, \n",
    "            num_heads=1, \n",
    "            dropout=0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(seq_input_size, seq_input_size),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(seq_input_size + static_input_size, 2), # combine static inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2, output_size), # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_x, static_x):\n",
    "        # x_seq_proj = self.input_fc(seq_x) # (batch, 4, 3) -> (batch, 4, hidden_size)\n",
    "        # x_encoded = self.pos_encoder(seq_x)\n",
    "        x_trans, _ = self.attn(seq_x, seq_x, seq_x) # (batch, 4, hidden_size)\n",
    "\n",
    "        # x_trans = self.mlp(x_trans)\n",
    "        \n",
    "        x_final = x_trans[:, -1, :]  # take the output of the last time step\n",
    "        # concatenate RNN output with static features\n",
    "        combined = torch.cat((x_final, static_x), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd32b8",
   "metadata": {},
   "source": [
    "# train / eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device): \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for seq_inputs, static_inputs, labels in train_loader:\n",
    "        seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(seq_inputs, static_inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq_inputs, static_inputs, labels in test_loader:\n",
    "            seq_inputs, static_inputs, labels = seq_inputs.to(device), static_inputs.to(device), labels.to(device)\n",
    "            preds = model(seq_inputs, static_inputs)\n",
    "            preds = preds.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bd35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    loss_prog = []\n",
    "    acc_prog = []\n",
    "    acc_h1_prog = []\n",
    "    acc_h6_prog = []\n",
    "\n",
    "    epochs_without_improvement = 0 # for early stopping\n",
    "    best_loss = float('inf')\n",
    "    patience = 20\n",
    "    final_epoch = epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = train(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        # append accuracy\n",
    "        acc = test(model, test_loader, device)\n",
    "        acc_h1 = test(model, test_loader_h1, device)\n",
    "        acc_h6 = test(model, test_loader_h6, device)\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss: {loss:.4f} | overall: {acc:.4f} | H1 {acc_h1:.4f} | H6 {acc_h6:.4f}\")\n",
    "\n",
    "        loss_prog.append(loss)\n",
    "        acc_prog.append(acc)\n",
    "        acc_h1_prog.append(acc_h1)\n",
    "        acc_h6_prog.append(acc_h6)\n",
    "\n",
    "        # early stopping\n",
    "        # if loss < best_loss:\n",
    "        #     best_loss = loss\n",
    "        #     epochs_without_improvement = 0\n",
    "        # else:\n",
    "        #     epochs_without_improvement += 1\n",
    "\n",
    "        # if epochs_without_improvement > patience: \n",
    "        #     print(f\"Early stopping triggered: epoch {epoch+1} best_loss {best_loss:.4f}\")\n",
    "        #     final_epoch = epoch+1\n",
    "        #     break\n",
    "\n",
    "    return loss_prog, acc_prog, acc_h1_prog, acc_h6_prog, final_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f45961",
   "metadata": {},
   "source": [
    "# running experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c0ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyGRU(\n",
      "  (gru): GRU(2, 2, batch_first=True)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TinyGRU().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "146d430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0205db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.6908 | overall: 0.5164 | H1 0.6786 | H6 0.3788\n",
      "Epoch 10: Loss: 0.6653 | overall: 0.6803 | H1 0.6786 | H6 0.6818\n",
      "Epoch 20: Loss: 0.6557 | overall: 0.6803 | H1 0.6786 | H6 0.6818\n",
      "Epoch 30: Loss: 0.6455 | overall: 0.6885 | H1 0.6429 | H6 0.7273\n",
      "Epoch 40: Loss: 0.6333 | overall: 0.6967 | H1 0.6607 | H6 0.7273\n",
      "Epoch 50: Loss: 0.6316 | overall: 0.6803 | H1 0.6250 | H6 0.7273\n",
      "Epoch 60: Loss: 0.6163 | overall: 0.6967 | H1 0.6607 | H6 0.7273\n",
      "Epoch 70: Loss: 0.6123 | overall: 0.7131 | H1 0.6786 | H6 0.7424\n",
      "Epoch 80: Loss: 0.5946 | overall: 0.7295 | H1 0.6964 | H6 0.7576\n",
      "Epoch 90: Loss: 0.6014 | overall: 0.7131 | H1 0.6964 | H6 0.7273\n",
      "Epoch 100: Loss: 0.5822 | overall: 0.6967 | H1 0.6964 | H6 0.6970\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_prog, acc_prog, acc_h1_prog, acc_h6_prog, final_epoch = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3395551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = {\n",
    "#     # \"RNN\": RNN().to(device),\n",
    "#     # \"LSTM\": LSTM().to(device),\n",
    "#     \"GRU\": GRU().to(device),\n",
    "#     # \"TinyGRU\": TinyGRU().to(device),\n",
    "#     # \"Transformer\": TransformerEncoderPositionalEncoding().to(device),\n",
    "#     # \"SelfAttention\": SelfAttentionOnly().to(device),\n",
    "#     # \"TinyAttentionNoProj\": TinyAttentionNoProj().to(device),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b82e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# for model_name, model in model_dict.items():\n",
    "#     print(f\"\\nTraining model: {model_name}\")\n",
    "#     print(model)\n",
    "#     loss_prog, acc_prog, acc_h1_prog, acc_h6_prog, final_epoch = train_and_evaluate(model, train_loader, criterion, optimizer, device, epochs=epochs)\n",
    "#     model_dict[model_name] = {\n",
    "#         \"model\": model,\n",
    "#         \"loss_prog\": loss_prog,\n",
    "#         \"acc_prog\": acc_prog,\n",
    "#         \"acc_h1_prog\": acc_h1_prog,\n",
    "#         \"acc_h6_prog\": acc_h6_prog,\n",
    "#         \"final_epoch\": final_epoch\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "632187f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9aebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training and testing loss\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# for model_name, data in model_dict.items():\n",
    "#     loss_prog = data[\"loss_prog\"]\n",
    "#     final_epoch = data[\"final_epoch\"]\n",
    "#     plt.plot(range(final_epoch), loss_prog, label=f'{model_name} Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss over epochs')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b1546dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot testing accuracy\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# for model_name, data in model_dict.items():\n",
    "#     acc_prog = data[\"acc_prog\"]\n",
    "#     final_epoch = data[\"final_epoch\"]\n",
    "#     plt.plot(range(final_epoch), acc_prog, label=f'{model_name} Test Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.title('Test Accuracy over epochs')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389aa0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3234f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366201b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
