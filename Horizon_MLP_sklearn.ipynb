{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23eef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47c860",
   "metadata": {},
   "source": [
    "# vanilla pipeline\n",
    "## Data Processing\n",
    "features: \n",
    "- `gameLength` [5, 10]\n",
    "- `uc` - uncertainty condition: [1, 2, 3]\n",
    "- `r*` - rewards (unnormalized)\n",
    "- `c*` - choice: [1, 2]\n",
    "- `rt*` - response time\n",
    "\n",
    "predict\n",
    "- `c5` - the first choice of participants: [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/allHorizonData_cut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039e162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Data (X) ---\n",
      "   gameLength  uc  r1  r2  r3  r4  c1  c2  c3  c4\n",
      "0           5   3  66  80  29  75   2   2   1   2\n",
      "1          10   3  69  50  51  64   2   2   1   2\n",
      "2          10   2  31  43  26  36   2   1   2   1\n",
      "3          10   2  65  77  52  73   1   2   2   1\n",
      "4          10   2  70  19  43  41   2   1   2   1\n",
      "\n",
      "--- Target Data (y) ---\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: c5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features = ['gameLength', 'uc', 'r1', 'r2', 'r3', 'r4', 'c1', 'c2', 'c3', 'c4']\n",
    "target = 'c5'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "y = y-1 # binary CE only takes in 0, 1\n",
    "\n",
    "print(\"--- Feature Data (X) ---\")\n",
    "print(X.head())\n",
    "print(\"\\n--- Target Data (y) ---\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1e5975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (15360, 10)\n",
      "X_test (3840, 10)\n",
      "y_train (15360,)\n",
      "y_test (3840,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize per feature\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# sanity check\n",
    "print(f\"X_train {X_train.shape}\")\n",
    "print(f\"X_test {X_test.shape}\")\n",
    "print(f\"y_train {y_train.shape}\")\n",
    "print(f\"y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f745a93",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d78730",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60283204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, ), \n",
    "    max_iter=500, \n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20)\n",
    "\n",
    "print(\"Training\")\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a09aca",
   "metadata": {},
   "source": [
    "predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197e9bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.80\n",
      "--- report --- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1941\n",
      "           1       0.79      0.80      0.80      1899\n",
      "\n",
      "    accuracy                           0.80      3840\n",
      "   macro avg       0.80      0.80      0.80      3840\n",
      "weighted avg       0.80      0.80      0.80      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'--- report --- \\n{report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd25e5",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41171894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(features):\n",
    "    target = 'c5'\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    y = y-1 # binary CE only takes in 0, 1\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # normalize per feature\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03cd8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_base = ['gameLength', 'uc']\n",
    "feature_r_c = ['gameLength', 'uc', 'r1', 'r2', 'r3', 'r4', 'c1', 'c2', 'c3', 'c4']\n",
    "feature_r_c_rt = ['gameLength', 'uc', 'r1', 'r2', 'r3', 'r4', 'c1', 'c2', 'c3', 'c4', 'r1', 'r2', 'r3', 'r4']\n",
    "\n",
    "feature_sets = [feature_base, feature_r_c, feature_r_c_rt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f761aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "archs_2_layers = [\n",
    "    (8, ),\n",
    "    (16, ),\n",
    "    (32, ),\n",
    "    (64, ),\n",
    "    (128, ),\n",
    "    (256, ),\n",
    "]\n",
    "\n",
    "archs_3_layers = [\n",
    "    (256, 128), \n",
    "    (128, 64), \n",
    "    (64, 32), \n",
    "    (32, 16), \n",
    "    (16, 8), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "258dcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(archs, feature_sets):\n",
    "    output = []\n",
    "\n",
    "    for feature in feature_sets:\n",
    "        print(f'feature: {len(feature)}')\n",
    "        X_train, X_test, y_train, y_test = get_data(feature)\n",
    "\n",
    "        for arch in archs:\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=arch, \n",
    "                max_iter=500, \n",
    "                random_state=42,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=20\n",
    "            )\n",
    "\n",
    "            mlp.fit(X_train, y_train)\n",
    "            y_pred = mlp.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            output.append({\n",
    "                'feature': len(feature), \n",
    "                'architecture': arch, \n",
    "                'accuracy': accuracy,\n",
    "            })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6066aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- running 2-layer MLP experiment ---\n",
      "feature: 2\n",
      "feature: 10\n",
      "feature: 14\n",
      "--- running 3-layer MLP experiment ---\n",
      "feature: 2\n",
      "feature: 10\n",
      "feature: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"--- running 2-layer MLP experiment ---\")\n",
    "arch_2_output = experiment(archs_2_layers, feature_sets)\n",
    "\n",
    "print(\"--- running 3-layer MLP experiment ---\")\n",
    "arch_3_output = experiment(archs_3_layers, feature_sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af742c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2 Layer Summary ---\n",
      "    feature architecture  accuracy\n",
      "11       10       (256,)  0.799740\n",
      "17       14       (256,)  0.799479\n",
      "14       14        (32,)  0.798438\n",
      "8        10        (32,)  0.797135\n",
      "7        10        (16,)  0.796615\n",
      "--- 3 Layer Summary ---\n",
      "    feature architecture  accuracy\n",
      "13       14     (32, 16)  0.804167\n",
      "10       14   (256, 128)  0.802604\n",
      "8        10     (32, 16)  0.802083\n",
      "11       14    (128, 64)  0.801823\n",
      "9        10      (16, 8)  0.800781\n"
     ]
    }
   ],
   "source": [
    "arch_2_df = pd.DataFrame(arch_2_output)\n",
    "arch_3_df = pd.DataFrame(arch_3_output)\n",
    "\n",
    "best_model_2 = arch_2_df.sort_values(by='accuracy', ascending=False)\n",
    "best_model_3 = arch_3_df.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "print(\"--- 2 Layer Summary ---\")\n",
    "print(best_model_2.head())\n",
    "print(\"--- 3 Layer Summary ---\")\n",
    "print(best_model_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84ebfc",
   "metadata": {},
   "source": [
    "# per horizon prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c99bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
