{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb463fa9",
      "metadata": {
        "id": "fb463fa9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ddb73b72",
      "metadata": {
        "id": "ddb73b72"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è Config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = \"cpu\"  # For testing purposes, use CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ea74fdbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea74fdbc",
        "outputId": "d398f90c-ed3b-425d-d632-7cd578962065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c5d2b35",
      "metadata": {
        "id": "4c5d2b35"
      },
      "outputs": [],
      "source": [
        "class HorizonSeqDatasetWithContext(Dataset):\n",
        "    def __init__(self, df):\n",
        "        rewards = df[[f\"r{i}\" for i in range(1, 11)]].values\n",
        "        choices = df[[f\"c{i}\" for i in range(1, 11)]].values\n",
        "        game_lengths = df[\"gameLength\"].values\n",
        "        ucs = df[\"uc\"].values\n",
        "\n",
        "        choices = choices - 1  # Ensure binary [0,1]\n",
        "\n",
        "        self.inputs, self.targets, self.contexts = [], [], []\n",
        "\n",
        "        for r_seq, c_seq, gl, uc in zip(rewards, choices, game_lengths, ucs):\n",
        "            valid_steps = int(gl)\n",
        "            if valid_steps <= 1:\n",
        "                continue\n",
        "            x = np.stack([r_seq[:valid_steps - 1], c_seq[:valid_steps - 1]], axis=1)\n",
        "            y = c_seq[1:valid_steps]\n",
        "            if not (np.isnan(x).any() or np.isnan(y).any()):\n",
        "                self.inputs.append(torch.tensor(x, dtype=torch.float32))\n",
        "                self.targets.append(torch.tensor(y, dtype=torch.float32))\n",
        "                self.contexts.append(torch.tensor([gl, uc], dtype=torch.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx], self.contexts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "svBT63XHJc3f",
      "metadata": {
        "id": "svBT63XHJc3f"
      },
      "outputs": [],
      "source": [
        "def variable_length_collate(batch):\n",
        "    input_seqs = [item[0] for item in batch]\n",
        "    target_seqs = [item[1] for item in batch]\n",
        "    contexts = [item[2] for item in batch]\n",
        "    return input_seqs, target_seqs, contexts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef829aa4",
      "metadata": {
        "id": "ef829aa4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and split dataset\n",
        "df = pd.read_csv(\"data/allHorizonData_cut.csv\")\n",
        "dataset = HorizonSeqDatasetWithContext(df)\n",
        "\n",
        "train_idx, val_idx = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(Subset(dataset, train_idx), batch_size=64, shuffle=True,\n",
        "                          collate_fn=variable_length_collate)\n",
        "\n",
        "val_loader = DataLoader(Subset(dataset, val_idx), batch_size=64,\n",
        "                        collate_fn=variable_length_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5c615eea",
      "metadata": {
        "id": "5c615eea"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class TinyGRUWithContext(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=2, context_dim=2):\n",
        "        super().__init__()\n",
        "        self.rnn_cell = nn.GRUCell(input_size=input_dim, hidden_size=hidden_dim)\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + context_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_seq, context):\n",
        "        # input_seq: [1, T, 2]\n",
        "        # context: [2]\n",
        "        T = input_seq.size(1)\n",
        "        h = torch.zeros(1, self.rnn_cell.hidden_size, device=input_seq.device)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = input_seq[:, t, :]\n",
        "            h = self.rnn_cell(x_t, h)\n",
        "            h_ctx = torch.cat([h, context.unsqueeze(0)], dim=1)  # [1, hidden + context]\n",
        "            out = self.output_layer(h_ctx)\n",
        "            outputs.append(out)\n",
        "\n",
        "        return torch.cat(outputs, dim=0).squeeze(1)  # [T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb77b57",
      "metadata": {
        "id": "ccb77b57"
      },
      "outputs": [],
      "source": [
        "\n",
        "# üèãÔ∏è Train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TinyGRUWithContext().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "for input_batch, target_batch, context_batch in train_loader:\n",
        "    for input_seq, target_seq, context in zip(input_batch, target_batch, context_batch):\n",
        "        input_seq = input_seq.unsqueeze(0).to(device)  # [1, T, 2]\n",
        "        target_seq = target_seq.to(device)             # [T]\n",
        "        context = context.to(device)                   # [2]\n",
        "\n",
        "        preds = model(input_seq, context)              # ‚úÖ pass both inputs here\n",
        "\n",
        "        loss = criterion(preds, target_seq)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        pred_bin = (preds > 0.5).float()\n",
        "        all_preds.extend(pred_bin.cpu().numpy())\n",
        "        all_labels.extend(target_seq.cpu().numpy())\n",
        "\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}, Accuracy = {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144aac75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "144aac75",
        "outputId": "278e7670-6628-45ec-b723-f756351fe290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy  : 0.5081\n",
            "Horizon 1 Accuracy: 0.5061\n",
            "Horizon 6 Accuracy: 0.5090\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds_all, labels_all = [], []\n",
        "preds_H1, labels_H1 = [], []\n",
        "preds_H6, labels_H6 = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input_batch, target_batch, context_batch in val_loader:\n",
        "        for input_seq, target_seq, context in zip(input_batch, target_batch, context_batch):\n",
        "            input_seq = input_seq.unsqueeze(0).to(device)   # [1, T, 2]\n",
        "            target_seq = target_seq.to(device)              # [T]\n",
        "            context = context.to(device)                    # [2]\n",
        "\n",
        "            preds = model(input_seq, context)               # [T]\n",
        "            pred_bin = (preds > 0.5).float()\n",
        "\n",
        "            preds_all.extend(pred_bin.cpu().numpy())\n",
        "            labels_all.extend(target_seq.cpu().numpy())\n",
        "\n",
        "            if context[0].item() == 5:\n",
        "                preds_H1.extend(pred_bin.cpu().numpy())\n",
        "                labels_H1.extend(target_seq.cpu().numpy())\n",
        "            elif context[0].item() == 10:\n",
        "                preds_H6.extend(pred_bin.cpu().numpy())\n",
        "                labels_H6.extend(target_seq.cpu().numpy())\n",
        "\n",
        "# üßÆ Accuracy calculations\n",
        "acc_all = accuracy_score(labels_all, preds_all)\n",
        "acc_H1 = accuracy_score(labels_H1, preds_H1)\n",
        "acc_H6 = accuracy_score(labels_H6, preds_H6)\n",
        "\n",
        "# üì¢ Print\n",
        "print(f\"\\nOverall Accuracy  : {acc_all:.4f}\")\n",
        "print(f\"Horizon 1 Accuracy: {acc_H1:.4f}\")\n",
        "print(f\"Horizon 6 Accuracy: {acc_H6:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5963d6",
      "metadata": {
        "id": "3c5963d6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "coco",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
