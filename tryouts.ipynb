{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74f6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/allHorizonData_cut.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff420dbb",
   "metadata": {},
   "source": [
    "# data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d91e1",
   "metadata": {},
   "source": [
    "base data\n",
    "- based on `gameLength` and `uc` \n",
    "- predict `c5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dea0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtered = df[df[\"c5\"].notna()][[\"gameLength\", \"uc\", \"c5\"]].dropna()\n",
    "\n",
    "# One-hot encode gameLength and uc\n",
    "X = pd.get_dummies(df_filtered[[\"gameLength\", \"uc\"]], columns=[\"gameLength\", \"uc\"])\n",
    "y = df_filtered[\"c5\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801ce80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gameLength_5  gameLength_10   uc_1   uc_2   uc_3\n",
      "0          True          False  False  False   True\n",
      "1         False           True  False  False   True\n",
      "2         False           True  False   True  False\n",
      "3         False           True  False   True  False\n",
      "4         False           True  False   True  False\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61d8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    2\n",
      "Name: c5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60569d7",
   "metadata": {},
   "source": [
    "additional info\n",
    "- `c1-5` `r1-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_features = ['gameLength', 'uc', 'r1', 'r2', 'r3', 'r4', 'c1', 'c2', 'c3', 'c4', 'c5']\n",
    "df_extended = df[extended_features].dropna()\n",
    "\n",
    "X_ext = pd.get_dummies(df_extended.drop(columns=\"c5\"), columns=[\"gameLength\", \"uc\", \"c1\", \"c2\", \"c3\", \"c4\"])\n",
    "y = df_extended[\"c5\"]\n",
    "\n",
    "X_train_ext, X_test_ext, y_train, y_test = train_test_split(X_ext, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e350cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   r1  r2  r3  r4  gameLength_5  gameLength_10   uc_1   uc_2   uc_3   c1_1  \\\n",
      "0  66  80  29  75          True          False  False  False   True  False   \n",
      "1  69  50  51  64         False           True  False  False   True  False   \n",
      "2  31  43  26  36         False           True  False   True  False  False   \n",
      "3  65  77  52  73         False           True  False   True  False   True   \n",
      "4  70  19  43  41         False           True  False   True  False  False   \n",
      "\n",
      "    c1_2   c2_1   c2_2   c3_1   c3_2   c4_1   c4_2  \n",
      "0   True  False   True   True  False  False   True  \n",
      "1   True  False   True   True  False  False   True  \n",
      "2   True   True  False  False   True   True  False  \n",
      "3  False  False   True  False   True   True  False  \n",
      "4   True   True  False  False   True   True  False  \n"
     ]
    }
   ],
   "source": [
    "print(X_ext.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694607d",
   "metadata": {},
   "source": [
    "# vanilla logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f702ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53      1941\n",
      "           2       0.52      0.53      0.53      1899\n",
      "\n",
      "    accuracy                           0.53      3840\n",
      "   macro avg       0.53      0.53      0.53      3840\n",
      "weighted avg       0.53      0.53      0.53      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "report_log = classification_report(y_test, y_pred_log)\n",
    "print(report_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.49      0.52      1941\n",
      "           2       0.53      0.58      0.55      1899\n",
      "\n",
      "    accuracy                           0.54      3840\n",
      "   macro avg       0.54      0.54      0.54      3840\n",
      "weighted avg       0.54      0.54      0.54      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model_ext = LogisticRegression(max_iter=1000)\n",
    "log_model_ext.fit(X_train_ext, y_train)\n",
    "\n",
    "y_pred_ext = log_model_ext.predict(X_test_ext)\n",
    "report_ext = classification_report(y_test, y_pred_ext)\n",
    "print(report_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb6e52",
   "metadata": {},
   "source": [
    "# dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d7ae08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae37bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.64      0.58      1941\n",
      "           2       0.52      0.40      0.45      1899\n",
      "\n",
      "    accuracy                           0.52      3840\n",
      "   macro avg       0.52      0.52      0.51      3840\n",
      "weighted avg       0.52      0.52      0.51      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dtree_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dtree_base = dtree_model.predict(X_test)\n",
    "report_dtree_base = classification_report(y_test, y_pred_dtree_base)\n",
    "print(report_dtree_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eec261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.68      0.70      1941\n",
      "           2       0.69      0.73      0.71      1899\n",
      "\n",
      "    accuracy                           0.70      3840\n",
      "   macro avg       0.70      0.70      0.70      3840\n",
      "weighted avg       0.70      0.70      0.70      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtree_ext_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dtree_ext_model.fit(X_train_ext, y_train)\n",
    "\n",
    "y_pred_dtree_ext = dtree_ext_model.predict(X_test_ext)\n",
    "report_dtree_ext = classification_report(y_test, y_pred_dtree_ext)\n",
    "print(report_dtree_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52ff65",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7215187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d0b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.40      0.46      1941\n",
      "           2       0.52      0.65      0.58      1899\n",
      "\n",
      "    accuracy                           0.53      3840\n",
      "   macro avg       0.53      0.53      0.52      3840\n",
      "weighted avg       0.53      0.53      0.52      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_base_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_base_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_base = rf_base_model.predict(X_test)\n",
    "report_rf_base = classification_report(y_test, y_pred_rf_base)\n",
    "print(report_rf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ea121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.71      0.72      1941\n",
      "           2       0.71      0.74      0.72      1899\n",
      "\n",
      "    accuracy                           0.72      3840\n",
      "   macro avg       0.72      0.72      0.72      3840\n",
      "weighted avg       0.72      0.72      0.72      3840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_ext_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_ext_model.fit(X_train_ext, y_train)\n",
    "\n",
    "y_pred_rf_ext = rf_ext_model.predict(X_test_ext)\n",
    "report_rf_ext = classification_report(y_test, y_pred_rf_ext)\n",
    "print(report_rf_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425c7e9",
   "metadata": {},
   "source": [
    "## split groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_h1 = df_extended[\"gameLength\"] == 5\n",
    "is_h6 = df_extended[\"gameLength\"] == 10\n",
    "\n",
    "X_h1 = X_ext[is_h1]\n",
    "y_h1 = y[is_h1]\n",
    "\n",
    "X_h6 = X_ext[is_h6]\n",
    "y_h6 = y[is_h6]\n",
    "\n",
    "X_train_h1, X_test_h1, y_train_h1, y_test_h1 = train_test_split(X_h1, y_h1, test_size=0.2, random_state=42)\n",
    "X_train_h6, X_test_h6, y_train_h6, y_test_h6 = train_test_split(X_h6, y_h6, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c800259",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# RF for Horizon 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rf_h1 \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m rf_h1\u001b[38;5;241m.\u001b[39mfit(X_train_h1, y_train_h1)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorizon 1 Performance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test_h1, rf_h1\u001b[38;5;241m.\u001b[39mpredict(X_test_h1)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# RF for Horizon 1\n",
    "rf_h1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_h1.fit(X_train_h1, y_train_h1)\n",
    "print(\"Horizon 1 Performance:\\n\", classification_report(y_test_h1, rf_h1.predict(X_test_h1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f91354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF for Horizon 6\n",
    "rf_h6 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_h6.fit(X_train_h6, y_train_h6)\n",
    "print(\"Horizon 6 Performance:\\n\", classification_report(y_test_h6, rf_h6.predict(X_test_h6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
